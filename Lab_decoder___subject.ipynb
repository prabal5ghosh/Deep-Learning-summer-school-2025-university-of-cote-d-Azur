{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabal5ghosh/Deep-Learning-summer-school-2025-university-of-cote-d-Azur/blob/main/Lab_decoder___subject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCPBiboYArv5"
      },
      "source": [
        "<center><img width=60% src=\"http://www.i3s.unice.fr/~lingrand/efeliaUnica.png\"><br/><br/>\n",
        "<font size=+3><b>Decoder only</b></font><br/><br/>\n",
        "<font size=+1>Célia D'Cruz, Diane Lingrand, and Frédéric Precioso<br/><br/>\n",
        "    2025 - June/July</font><br/>\n",
        "    <img width=14% src=\"http://www.i3s.unice.fr/~lingrand/cc-long.png\">\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvIRELISAtR-"
      },
      "source": [
        "<div> This notebook introduces the decoder architecture, including its causal multi-head attention mechanism, and shows a method to pretrain it and to generate text.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ap1XqOuAtR_"
      },
      "source": [
        "## Imports and device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n16a6lNpAtR_"
      },
      "source": [
        "<font color=\"red\">Use a GPU to speed up computations.</font>\n",
        "If your laptop does not have a GPU, you can use Google Colab or Kaggle.\n",
        "\n",
        "To enable GPU backend in Google Colab for your notebook:\n",
        "\n",
        "1.   Runtime (top left corner) -> Change runtime type\n",
        "2.   Put GPU as \"Hardware accelerator\"\n",
        "3.   Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC_9FQa1AtR_",
        "outputId": "8c5ee9b4-9af1-4321-d11d-8161da374071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.67.1)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Downloading boto3-1.38.42-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from bertviz) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: IPython>=7.14 in /usr/local/lib/python3.11/dist-packages (from bertviz) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (75.2.0)\n",
            "Collecting jedi>=0.16 (from IPython>=7.14->bertviz)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.14->bertviz) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0->bertviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.5.3)\n",
            "Collecting botocore<1.39.0,>=1.38.42 (from boto3->bertviz)\n",
            "  Downloading botocore-1.38.42-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->bertviz)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.42->boto3->bertviz) (2.9.0.post0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=2.0->bertviz) (1.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython>=7.14->bertviz) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython>=7.14->bertviz) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython>=7.14->bertviz) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.42->boto3->bertviz) (1.17.0)\n",
            "Downloading bertviz-1.4.1-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.42-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.42-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, bertviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bertviz-1.4.1 boto3-1.38.42 botocore-1.38.42 jedi-0.19.2 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 s3transfer-0.13.0\n"
          ]
        }
      ],
      "source": [
        "# all the imports needed in the lab\n",
        "!pip install bertviz\n",
        "import bertviz\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "import requests\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OccmvCrArwA"
      },
      "source": [
        "Check that your GPU is recognized by running the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2vtkdPyAtSA",
        "outputId": "fd1de12a-a03a-467c-d38e-e14371f5b270"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# making the code device agnostic\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHkHPguxAtSA"
      },
      "source": [
        "# GPT2 decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-oM70l5AtSA"
      },
      "source": [
        "In this lab, we will use the pretrained [GPT2 decoder model](https://huggingface.co/openai-community/gpt2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCp7tIgBAtSA"
      },
      "source": [
        "Note the large vocabulary size of the GPT2 tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "a8c523971fd845939993e9144a5139eb",
            "d6563a0c2a294c11b483987484bc4a51",
            "341e5e93a626419c96846ff01c7e7124",
            "3c478be8774d4011b6e6f2f3f379134e",
            "dd1d67ffff9e42cfabef92adc63feb7f",
            "30f8d472b34a42ebbf655940f68e2d48",
            "f04aaba5c50848548d4dc6c3a58d30e1",
            "ca8b0bcd55b148ec9895fc316945d7f1",
            "ecfa102a568c42ef99956bba507e45f9",
            "b4f5921576ba481d92f258b663823f3c",
            "2c0557fd332847a4b2f4a7feb2a03de0",
            "6226e48b387248a0b984c2cbdc067893",
            "84ec0456a72d4b43a6cb85b79e067ebd",
            "bfff00db34a44e6a946ff58bc3a1892f",
            "b31e9c6ec24f4ac794996bd849cfdfe4",
            "00e694b67e524e53930b82628f299271",
            "fe2faf1c55494a7caa76f816db80fb0f",
            "e7eefe67152146058c081a5202710865",
            "da5d2388028847d89ca0fde6e2ee90c6",
            "a5c797dfd5724c8988eb49faad3d0fc9",
            "bd8041bd2ebc465c8d965887e0df88ef",
            "0932235d50354d5d8ae914003497c88c",
            "4b0048539c40491b90aaef202a1711e7",
            "84ddd951cfa242ef8eb630ab6b76c70b",
            "21312f3035d8470bb359349b35510922",
            "c42fc53dd46c4d98becc91997e0b8f8c",
            "d41af6102e284b569318961580dd922c",
            "d47f67352e07402d963436e7cd3ec8c4",
            "6f984a82a0af4370b0d9040dbab75ee3",
            "c5efc2e6763d413aa1d4a8cd02da692a",
            "7e2dd6cbd5244cae9c344bd50cfcbd6c",
            "6c5ce8474f7a43aaa14e6dee0fc70e41",
            "93c899e68a534ab09ea565c26374c4bc",
            "0d066d13e5964144b06461962bc2145f",
            "8c3b07c72bc34bcab69c694692138135",
            "e4708c17451d46459769665f900d3cbc",
            "7c1556140ffe46c9b354015b11436ccd",
            "41808acf48ae46d6b92e281b5b13b063",
            "2276528dd5214d9485fca32830999f0e",
            "c60700cbc8234eee95341cc367f07301",
            "11c65cd636b14eb3bb16620d9909a534",
            "cfe496d5a7a2487f8e09900aec32ad47",
            "f687a4d3bc3a4b34ad628c9082735f79",
            "a3f85baaa4e04e348e629ed12bef1678",
            "736d2f239d0749bf9d485eb65b18eeab",
            "2d4b27d925e04a558930ad88430e4627",
            "aef669c3f1ee4c5ebace644ef5a50c6a",
            "840c74ca21cd45daa51a5fcf52972ba0",
            "bb8452d3b33c4904a240bf085664fc5a",
            "18cf0d887fdc4fe78f837e0c020cf876",
            "fb111fcc89744dcc91ce942c3a018561",
            "10422ab055974b9082726c2bfae18aa8",
            "a0cfd2b3610c47d9a19feaf2a3ba13fc",
            "224fae8dc3444eb1854cd08f1505cf9a",
            "ff14000023fe4b65b3b3a1699563d63b"
          ]
        },
        "id": "dTeMGJShAtSB",
        "outputId": "59e440a5-8e0a-4abe-d989-1ed819014c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8c523971fd845939993e9144a5139eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6226e48b387248a0b984c2cbdc067893"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b0048539c40491b90aaef202a1711e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d066d13e5964144b06461962bc2145f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "736d2f239d0749bf9d485eb65b18eeab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer vocab size = 50257\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "print(f\"tokenizer vocab size = {tokenizer.vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7zTyXIAAtSB"
      },
      "source": [
        "We load the GPT2 decoder model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8521000fbc094d9d9d0d4635fd7b32ae",
            "fff7344cd87644278d1d60eb2becbf32",
            "b799f74dc95e4aeaa8383de3945c80b9",
            "dcc598a34d644b068f1eba2747b6a335",
            "9373a2ca7c5242fe961ba4b026dda154",
            "9753eb2fae6d4766b10524f68bd9ca14",
            "5fe132b235f94d1e8c060cb6dd1372c6",
            "b9c5dcf85aa24a80a6d59e3d4239b502",
            "779e6f285901432d85629708011c056d",
            "dd1288eeacd644b291839c0b342c33c5",
            "c0f92c727c8342c6977df0efb83283a9"
          ]
        },
        "id": "rTGNxwfGAtSB",
        "outputId": "32712cd9-da90-4b0a-cb3a-c9e5513098e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8521000fbc094d9d9d0d4635fd7b32ae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "GPT2_model = AutoModel.from_pretrained(\"openai-community/gpt2\", output_attentions = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9IYDOLeAtSB"
      },
      "source": [
        "We retrieve a few configuration elements of the GPT2 tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2aM1CfdAtSB",
        "outputId": "2301ee4e-be9d-422c-f84e-4e879ec14524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'vocab_size': 50257, 'emb_dim': 768, 'context_length': 1024}\n"
          ]
        }
      ],
      "source": [
        "config_model = {\n",
        "    \"vocab_size\" : tokenizer.vocab_size, # vocabulary size\n",
        "    \"emb_dim\" : GPT2_model.config.n_embd, # dimension of the token embeddings\n",
        "    \"context_length\" : GPT2_model.config.n_positions, # maximum length of sequences\n",
        "}\n",
        "\n",
        "print(config_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtzFtuj0AtSB"
      },
      "source": [
        "# Causal Multihead Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDBJYvvvArwE"
      },
      "source": [
        "## Self Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WbodNoyArwE"
      },
      "source": [
        "In the previous lab, we implemented a simple version of the self-attention. Here, we add keys, queries, values, and a scaling factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_1wZfAvArwE"
      },
      "source": [
        "\\begin{equation}\n",
        "Attention(Q, K, V) = \\mathrm{softmax}(\\frac{Q*K^{T}}{dim^{0.5}}) * V\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqqTtmTTArwE"
      },
      "source": [
        "The Query matrix Q, the Key matrix K, and the Value matrix V are linear transformations of the input embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nUh3T6XArwE"
      },
      "source": [
        "Taking as input an embedding, compute the Q, K and V matrices, and implement the self-attention mechanism following the aforementioned formula.\n",
        "\n",
        "- Hint 1: linear transformations can be done using [torch.nn.Linear](https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
        "- Hint 2: the transpose of the K matrix be can be done using [torch.Tensor.transpose](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.transpose.html) or [torch.transpose](https://docs.pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose).\n",
        "- Hint 3: the dimensions of a matrix can be retrieved using [torch.Tensor.shape](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.shape.html) or [torch.Tensor.size](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.size.html#torch.Tensor.size).\n",
        "- Hint 4: the @ operator can be used for matrix multiplication.\n",
        "- Hint 5: you can choose the dimension to which the [torch.softmax](https://docs.pytorch.org/docs/stable/generated/torch.softmax.html) is applied with the \"dim\" parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LAd46M3-ArwF"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SelfAttention(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x): # x represents embeddings # dim = [batch_size, num_tokens, emb_dim]    # x: [batch_size, num_tokens, d_in]\n",
        "        keys = self.W_key(x) # linear transformation of the input embeddings\n",
        "        queries = self.W_query(x) # linear transformation of the input embeddings\n",
        "        values = self.W_value(x) # linear transformation of the input embeddings\n",
        "\n",
        "        attn_scores = torch.matmul(queries, keys.transpose(-2, -1)) # Q * Kt # matrix multiplication between queries, and keys transposed in the last 2 dimensions # dim = [batch_size, num_tokens, num_tokens]\n",
        "        attn_weights =  F.softmax(attn_scores / math.sqrt(queries.shape[-1])) # softmax(attn_scores / sqrt(dim of embedding)) # attention scores rescaled with the square root of the embedding dimension, and normalized with softmax (be careful when choosing the dimension to which you apply the softmax)\n",
        "\n",
        "        context_vec = torch.matmul(attn_weights, values) # attn_weights * V # weighted average between the attention weights and the values (matrix multiplication)\n",
        "        return context_vec # contextualized embeddings # dim = [batch_size, num_tokens, emb_dim]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YldLhEKOArwF"
      },
      "source": [
        "For simplicity, we generate random embeddings with the shape of [batch_size, num_tokens, emb_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ARiszLArwF",
        "outputId": "864c09ab-4bd9-451c-a6f4-9f74e00043b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 11, 768])\n"
          ]
        }
      ],
      "source": [
        "random_embeddings = torch.rand(3, 11, config_model[\"emb_dim\"])\n",
        "print(random_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA5W0R6LArwF",
        "outputId": "53ec2b6a-8c4c-4776-ae3d-fa2749bf94e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contextualized embeddings of shape torch.Size([3, 11, 768])\n",
            "tensor([[[ 0.1665,  1.7948,  0.5903,  ...,  0.6676, -0.5569, -0.9453],\n",
            "         [-0.2074,  1.1920,  0.6658,  ...,  0.3312, -1.2694, -0.2969],\n",
            "         [ 0.3152,  1.5022,  1.2811,  ...,  0.7240, -1.3026, -0.4614],\n",
            "         ...,\n",
            "         [ 0.1490,  1.3958,  0.8943,  ...,  0.3246, -1.0314, -0.6124],\n",
            "         [ 0.3803,  1.0387,  0.5496,  ...,  0.2170, -0.4680, -0.7108],\n",
            "         [ 0.2422,  1.0641,  1.3300,  ...,  1.1255, -0.8299, -0.1949]],\n",
            "\n",
            "        [[ 0.5289,  1.5645,  1.4235,  ...,  0.2874, -0.9026, -0.2129],\n",
            "         [-0.4320,  1.6427,  0.6476,  ...,  0.5956, -0.8328, -0.0728],\n",
            "         [ 0.4413,  1.3821,  1.0507,  ...,  0.1128, -0.3071, -0.4360],\n",
            "         ...,\n",
            "         [-0.1875,  1.5299,  1.4705,  ...,  0.6848, -0.6144, -0.8049],\n",
            "         [ 0.3746,  1.8716,  1.4524,  ...,  0.7550, -0.3269, -0.3200],\n",
            "         [-0.0887,  1.7264,  0.6117,  ...,  0.1574, -0.4797, -0.3937]],\n",
            "\n",
            "        [[-0.5415,  1.3125,  1.4629,  ...,  0.6647, -1.1703, -0.3989],\n",
            "         [-0.2602,  1.1186,  0.6273,  ...,  0.8099, -1.0248, -0.9064],\n",
            "         [-0.0117,  1.6812,  1.2535,  ...,  0.8254, -0.7078, -0.8654],\n",
            "         ...,\n",
            "         [ 0.1760,  1.5351,  1.3149,  ...,  0.6874, -0.7248, -0.9761],\n",
            "         [-0.1743,  1.9788,  1.2172,  ...,  0.1411, -0.5496, -1.0541],\n",
            "         [ 0.1097,  1.3617,  1.1950,  ...,  0.6475, -1.2118, -0.5401]]],\n",
            "       grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-937932367.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights =  F.softmax(attn_scores / math.sqrt(queries.shape[-1])) # softmax(attn_scores / sqrt(dim of embedding)) # attention scores rescaled with the square root of the embedding dimension, and normalized with softmax (be careful when choosing the dimension to which you apply the softmax)\n"
          ]
        }
      ],
      "source": [
        "self_attention_block = SelfAttention(config_model[\"emb_dim\"], config_model[\"emb_dim\"])\n",
        "contextualized_embeddings = self_attention_block(random_embeddings)\n",
        "print(f\"contextualized embeddings of shape {contextualized_embeddings.shape}\")\n",
        "print(contextualized_embeddings - random_embeddings) # contextualized embeddings are different from the initially non contextualized embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOCbCpUAArwF"
      },
      "source": [
        "Now that we created the core of the attention mechanism in transformers, we can extend it over multiple heads, where we divide the attention mechanism into multiple “heads” that operate independently. This is called multi-head attention mechanism. For the sake of simplicity, we provide you with the implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k0x_VkIDAtSC"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, dropout, num_heads, qkv_bias=False, output_attention_weights = True):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "        self.output_attention_weights = output_attention_weights\n",
        "\n",
        "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x): # embeddings (batch_size, num_tokens, d_in)\n",
        "        num_tokens = x.shape[-2]\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (batch_size, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (batch_size, num_tokens, d_out) -> (batch_size, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(-1, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(-1, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(-1, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (batch_size, num_tokens, num_heads, head_dim) -> (batch_size, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(-2, -3)\n",
        "        queries = queries.transpose(-2, -3)\n",
        "        values = values.transpose(-2, -3)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention)\n",
        "        attn_scores = queries @ keys.transpose(-1, -2)  # Dot product for each head\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / self.head_dim ** 0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (batch_size, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(-2, -3)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(-1, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return (context_vec, attn_weights) if self.output_attention_weights else (context_vec,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho71JngTAtSC"
      },
      "source": [
        "We instanciate the MultiHeadAttention class and provide it with the random embeddings as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ialAd_AyAtSC",
        "outputId": "43b3cc21-f105-4bf4-b231-ac863670f48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contextualized embeddings of shape torch.Size([3, 11, 768])\n",
            "attention weights of shape torch.Size([3, 2, 11, 11])\n"
          ]
        }
      ],
      "source": [
        "multihead_attention_block = MultiHeadAttention(config_model[\"emb_dim\"], config_model[\"emb_dim\"], 0.1, num_heads = 2, output_attention_weights = True)\n",
        "contextualized_embeddings, attn_weights = multihead_attention_block(random_embeddings)\n",
        "\n",
        "print(f\"contextualized embeddings of shape {contextualized_embeddings.shape}\") # [batch_size, num_tokens, emb_dim]\n",
        "print(f\"attention weights of shape {attn_weights.shape}\") # [batch_size, n_heads, num_tokens, num_tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXRjJbnkAtSC"
      },
      "source": [
        "We visualize the attention weight matrices with the [interactive BertViz tool](https://github.com/jessevig/bertviz). Associated with our random initial embeddings, we randomly chose a sequence of \"Hello\" tokens. Note that each token (on the left) attends to both preceding and following tokens in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "NBq3Zq_xAtSC",
        "outputId": "e332b67e-aff4-4f19-c64a-e37a87fe7d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attentions: 1 encoder layers, each with an attention matrix of shape torch.Size([1, 2, 11, 11])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "      \n",
              "        <div id=\"bertviz-4f9f97a4692b4d469b0868df121e68ed\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
              "            <span style=\"user-select:none\">\n",
              "                \n",
              "            </span>\n",
              "            <div id='vis'></div>\n",
              "        </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/**\n",
              " * @fileoverview Transformer Visualization D3 javascript code.\n",
              " *\n",
              " * Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
              " *\n",
              " * Change log:\n",
              " *\n",
              " * 02/01/19  Jesse Vig   Initial implementation\n",
              " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
              " * 01/19/21  Jesse Vig   Support light/dark modes\n",
              " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
              " * 05/03/21  Jesse Vig   Adjust visualization height dynamically\n",
              " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
              " **/\n",
              "\n",
              "require.config({\n",
              "  paths: {\n",
              "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
              "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "  }\n",
              "});\n",
              "\n",
              "requirejs(['jquery', 'd3'], function($, d3) {\n",
              "\n",
              "        const params = {\"attention\": [{\"name\": null, \"attn\": [[[[0.10261322557926178, 0.09967197477817535, 0.10471662878990173, 0.1038997694849968, 0.09983649104833603, 0.10672742128372192, 0.0, 0.09467925876379013, 0.1027178093791008, 0.09467300027608871, 0.10089392215013504], [0.10247872024774551, 0.09869556874036789, 0.10005058348178864, 0.1000746414065361, 0.1023896262049675, 0.10857154428958893, 0.1015227735042572, 0.09821164608001709, 0.10331778228282928, 0.0, 0.10330332815647125], [0.10497140884399414, 0.09207195788621902, 0.10707926005125046, 0.10070165991783142, 0.09988104552030563, 0.10489410161972046, 0.1053796112537384, 0.10011020302772522, 0.0, 0.0, 0.10006213188171387], [0.10361217707395554, 0.09122499823570251, 0.10280917584896088, 0.0, 0.09795103222131729, 0.10856793075799942, 0.10424041002988815, 0.09782327711582184, 0.10496597737073898, 0.09661659598350525, 0.099065400660038], [0.10492746531963348, 0.0982961356639862, 0.10253798216581345, 0.09748247265815735, 0.10278459638357162, 0.11140727251768112, 0.09786141663789749, 0.09840285032987595, 0.10260577499866486, 0.09170247614383698, 0.10310272872447968], [0.10093294084072113, 0.09938225895166397, 0.10557500272989273, 0.10064313560724258, 0.09358999878168106, 0.10638077557086945, 0.10733737051486969, 0.09995315968990326, 0.10161001235246658, 0.09176583588123322, 0.10394064337015152], [0.10046476125717163, 0.102973073720932, 0.10734346508979797, 0.09853053092956543, 0.0, 0.1072402372956276, 0.10158418118953705, 0.09359680861234665, 0.10474615544080734, 0.0979078859090805, 0.09786723554134369], [0.0, 0.09739644825458527, 0.10495445132255554, 0.0, 0.09758955240249634, 0.10278721898794174, 0.10292214155197144, 0.10269981622695923, 0.10587749630212784, 0.09299605339765549, 0.10312676429748535], [0.1027401015162468, 0.09552285820245743, 0.0, 0.0, 0.10002180933952332, 0.10706166923046112, 0.10142338275909424, 0.09799839556217194, 0.10051031410694122, 0.0957753136754036, 0.0], [0.1060720831155777, 0.09403406828641891, 0.0, 0.10006547719240189, 0.09810510277748108, 0.0, 0.10388315469026566, 0.10272551327943802, 0.10464261472225189, 0.0, 0.0], [0.1048453152179718, 0.09689179062843323, 0.0, 0.0, 0.09987125545740128, 0.10310930013656616, 0.10007871687412262, 0.09463348239660263, 0.10000962764024734, 0.09472097456455231, 0.10277771204710007]], [[0.10659626126289368, 0.10302228480577469, 0.09231570363044739, 0.09828221052885056, 0.10136548429727554, 0.09572184085845947, 0.0, 0.10417351126670837, 0.10217519849538803, 0.1066778153181076, 0.09559626132249832], [0.11260632425546646, 0.09987540543079376, 0.0, 0.09728659689426422, 0.09980254620313644, 0.09590300172567368, 0.11148575693368912, 0.0982823446393013, 0.09597833454608917, 0.0, 0.0], [0.10548647493124008, 0.10244583338499069, 0.10199815779924393, 0.10069859772920609, 0.0986950695514679, 0.0, 0.10699962824583054, 0.10394635796546936, 0.0974501296877861, 0.10350039601325989, 0.09200325608253479], [0.10253225266933441, 0.10279836505651474, 0.09838297963142395, 0.09929431229829788, 0.10263563692569733, 0.09716803580522537, 0.1071256771683693, 0.1032525897026062, 0.09979013353586197, 0.10350768268108368, 0.09462352842092514], [0.10690803825855255, 0.10128505527973175, 0.09791620075702667, 0.09565020352602005, 0.0, 0.0960053876042366, 0.10773812979459763, 0.0, 0.09639480710029602, 0.10870788246393204, 0.09311983734369278], [0.11030584573745728, 0.10108793526887894, 0.09638321399688721, 0.0, 0.10094886273145676, 0.09588728100061417, 0.1076977401971817, 0.09985519200563431, 0.0, 0.10940790921449661, 0.0930757150053978], [0.11019891500473022, 0.09928234666585922, 0.10202187299728394, 0.09843119233846664, 0.09479568898677826, 0.09477296471595764, 0.10866666585206985, 0.09921565651893616, 0.10064657777547836, 0.10790647566318512, 0.09517276287078857], [0.10522309690713882, 0.10367660224437714, 0.10252387821674347, 0.09481199830770493, 0.09825848788022995, 0.09678053855895996, 0.11233675479888916, 0.10498469322919846, 0.09429491311311722, 0.10068397223949432, 0.09753623604774475], [0.11126106977462769, 0.09581680595874786, 0.09803549945354462, 0.09711182117462158, 0.10118633508682251, 0.09841529279947281, 0.0, 0.09768938273191452, 0.09782659262418747, 0.1039622500538826, 0.100148506462574], [0.10366137325763702, 0.09677073359489441, 0.09804036468267441, 0.10082593560218811, 0.09918923676013947, 0.09725736826658249, 0.10854025930166245, 0.10118505358695984, 0.10165293514728546, 0.10427587479352951, 0.0], [0.10552319884300232, 0.0969487875699997, 0.10170379281044006, 0.10286693274974823, 0.09721381962299347, 0.09676181524991989, 0.10214473307132721, 0.0, 0.10059055685997009, 0.10736937075853348, 0.09994251281023026]]]], \"left_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"], \"right_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-4f9f97a4692b4d469b0868df121e68ed\", \"include_layers\": [0], \"include_heads\": [0, 1], \"total_heads\": 2}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[0.10261322557926178, 0.09967197477817535, 0.10471662878990173, 0.1038997694849968, 0.09983649104833603, 0.10672742128372192, 0.0, 0.09467925876379013, 0.1027178093791008, 0.09467300027608871, 0.10089392215013504], [0.10247872024774551, 0.09869556874036789, 0.10005058348178864, 0.1000746414065361, 0.1023896262049675, 0.10857154428958893, 0.1015227735042572, 0.09821164608001709, 0.10331778228282928, 0.0, 0.10330332815647125], [0.10497140884399414, 0.09207195788621902, 0.10707926005125046, 0.10070165991783142, 0.09988104552030563, 0.10489410161972046, 0.1053796112537384, 0.10011020302772522, 0.0, 0.0, 0.10006213188171387], [0.10361217707395554, 0.09122499823570251, 0.10280917584896088, 0.0, 0.09795103222131729, 0.10856793075799942, 0.10424041002988815, 0.09782327711582184, 0.10496597737073898, 0.09661659598350525, 0.099065400660038], [0.10492746531963348, 0.0982961356639862, 0.10253798216581345, 0.09748247265815735, 0.10278459638357162, 0.11140727251768112, 0.09786141663789749, 0.09840285032987595, 0.10260577499866486, 0.09170247614383698, 0.10310272872447968], [0.10093294084072113, 0.09938225895166397, 0.10557500272989273, 0.10064313560724258, 0.09358999878168106, 0.10638077557086945, 0.10733737051486969, 0.09995315968990326, 0.10161001235246658, 0.09176583588123322, 0.10394064337015152], [0.10046476125717163, 0.102973073720932, 0.10734346508979797, 0.09853053092956543, 0.0, 0.1072402372956276, 0.10158418118953705, 0.09359680861234665, 0.10474615544080734, 0.0979078859090805, 0.09786723554134369], [0.0, 0.09739644825458527, 0.10495445132255554, 0.0, 0.09758955240249634, 0.10278721898794174, 0.10292214155197144, 0.10269981622695923, 0.10587749630212784, 0.09299605339765549, 0.10312676429748535], [0.1027401015162468, 0.09552285820245743, 0.0, 0.0, 0.10002180933952332, 0.10706166923046112, 0.10142338275909424, 0.09799839556217194, 0.10051031410694122, 0.0957753136754036, 0.0], [0.1060720831155777, 0.09403406828641891, 0.0, 0.10006547719240189, 0.09810510277748108, 0.0, 0.10388315469026566, 0.10272551327943802, 0.10464261472225189, 0.0, 0.0], [0.1048453152179718, 0.09689179062843323, 0.0, 0.0, 0.09987125545740128, 0.10310930013656616, 0.10007871687412262, 0.09463348239660263, 0.10000962764024734, 0.09472097456455231, 0.10277771204710007]], [[0.10659626126289368, 0.10302228480577469, 0.09231570363044739, 0.09828221052885056, 0.10136548429727554, 0.09572184085845947, 0.0, 0.10417351126670837, 0.10217519849538803, 0.1066778153181076, 0.09559626132249832], [0.11260632425546646, 0.09987540543079376, 0.0, 0.09728659689426422, 0.09980254620313644, 0.09590300172567368, 0.11148575693368912, 0.0982823446393013, 0.09597833454608917, 0.0, 0.0], [0.10548647493124008, 0.10244583338499069, 0.10199815779924393, 0.10069859772920609, 0.0986950695514679, 0.0, 0.10699962824583054, 0.10394635796546936, 0.0974501296877861, 0.10350039601325989, 0.09200325608253479], [0.10253225266933441, 0.10279836505651474, 0.09838297963142395, 0.09929431229829788, 0.10263563692569733, 0.09716803580522537, 0.1071256771683693, 0.1032525897026062, 0.09979013353586197, 0.10350768268108368, 0.09462352842092514], [0.10690803825855255, 0.10128505527973175, 0.09791620075702667, 0.09565020352602005, 0.0, 0.0960053876042366, 0.10773812979459763, 0.0, 0.09639480710029602, 0.10870788246393204, 0.09311983734369278], [0.11030584573745728, 0.10108793526887894, 0.09638321399688721, 0.0, 0.10094886273145676, 0.09588728100061417, 0.1076977401971817, 0.09985519200563431, 0.0, 0.10940790921449661, 0.0930757150053978], [0.11019891500473022, 0.09928234666585922, 0.10202187299728394, 0.09843119233846664, 0.09479568898677826, 0.09477296471595764, 0.10866666585206985, 0.09921565651893616, 0.10064657777547836, 0.10790647566318512, 0.09517276287078857], [0.10522309690713882, 0.10367660224437714, 0.10252387821674347, 0.09481199830770493, 0.09825848788022995, 0.09678053855895996, 0.11233675479888916, 0.10498469322919846, 0.09429491311311722, 0.10068397223949432, 0.09753623604774475], [0.11126106977462769, 0.09581680595874786, 0.09803549945354462, 0.09711182117462158, 0.10118633508682251, 0.09841529279947281, 0.0, 0.09768938273191452, 0.09782659262418747, 0.1039622500538826, 0.100148506462574], [0.10366137325763702, 0.09677073359489441, 0.09804036468267441, 0.10082593560218811, 0.09918923676013947, 0.09725736826658249, 0.10854025930166245, 0.10118505358695984, 0.10165293514728546, 0.10427587479352951, 0.0], [0.10552319884300232, 0.0969487875699997, 0.10170379281044006, 0.10286693274974823, 0.09721381962299347, 0.09676181524991989, 0.10214473307132721, 0.0, 0.10059055685997009, 0.10736937075853348, 0.09994251281023026]]]], \"left_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"], \"right_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-4f9f97a4692b4d469b0868df121e68ed\", \"include_layers\": [0], \"include_heads\": [0, 1], \"total_heads\": 2} is a template marker that is replaced by actual params.\n",
              "        const config = {};\n",
              "\n",
              "        const MIN_X = 0;\n",
              "        const MIN_Y = 0;\n",
              "        const DIV_WIDTH = 970;\n",
              "        const THUMBNAIL_PADDING = 5;\n",
              "        const DETAIL_WIDTH = 300;\n",
              "        const DETAIL_ATTENTION_WIDTH = 140;\n",
              "        const DETAIL_BOX_WIDTH = 80;\n",
              "        const DETAIL_BOX_HEIGHT = 18;\n",
              "        const DETAIL_PADDING = 15;\n",
              "        const ATTN_PADDING = 0;\n",
              "        const DETAIL_HEADING_HEIGHT = 25;\n",
              "        const HEADING_TEXT_SIZE = 15;\n",
              "        const HEADING_PADDING = 5;\n",
              "        const TEXT_SIZE = 13;\n",
              "        const TEXT_PADDING = 5;\n",
              "        const LAYER_COLORS = d3.schemeCategory10;\n",
              "        const PALETTE = {\n",
              "            'light': {\n",
              "                'text': 'black',\n",
              "                'background': 'white',\n",
              "                'highlight': '#F5F5F5'\n",
              "            },\n",
              "            'dark': {\n",
              "                'text': '#ccc',\n",
              "                'background': 'black',\n",
              "                'highlight': '#222'\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function render() {\n",
              "\n",
              "            // Set global state variables\n",
              "\n",
              "            var attData = config.attention[config.filter];\n",
              "            config.leftText = attData.left_text;\n",
              "            config.rightText = attData.right_text;\n",
              "            config.attn = attData.attn;\n",
              "            config.numLayers = config.attn.length;\n",
              "            config.numHeads = config.attn[0].length;\n",
              "            config.thumbnailBoxHeight = 7 * (12 / config.totalHeads);\n",
              "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
              "            config.thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
              "            config.thumbnailWidth = (DIV_WIDTH - axisSize) / config.totalHeads;\n",
              "            config.detailHeight = Math.max(config.leftText.length, config.rightText.length) * DETAIL_BOX_HEIGHT + 2 * DETAIL_PADDING + DETAIL_HEADING_HEIGHT;\n",
              "            config.divHeight = Math.max(config.numLayers * config.thumbnailHeight + axisSize, config.detailHeight);\n",
              "\n",
              "            const vis = $(`#${config.rootDivId} #vis`)\n",
              "            vis.empty();\n",
              "            vis.attr(\"height\", config.divHeight);\n",
              "            config.svg = d3.select(`#${config.rootDivId} #vis`)\n",
              "                .append('svg')\n",
              "                .attr(\"width\", DIV_WIDTH)\n",
              "                .attr(\"height\", config.divHeight)\n",
              "                .attr(\"fill\", getBackgroundColor());\n",
              "\n",
              "            renderAxisLabels();\n",
              "\n",
              "            var i;\n",
              "            var j;\n",
              "            for (i = 0; i < config.numLayers; i++) {\n",
              "                for (j = 0; j < config.numHeads; j++) {\n",
              "                    renderThumbnail(i, j);\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function renderAxisLabels() {\n",
              "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
              "            const tableWidth = config.thumbnailWidth * config.heads.length;\n",
              "            config.svg.append(\"text\")\n",
              "                .text(\"Heads\")\n",
              "                .attr(\"fill\", \"black\")\n",
              "                .attr(\"font-weight\", \"bold\")\n",
              "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
              "                .attr(\"x\", axisSize + tableWidth / 2)\n",
              "                .attr(\"text-anchor\", \"middle\")\n",
              "                .attr(\"y\", 0)\n",
              "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
              "            for (let i = 0; i < config.numHeads; i++) {\n",
              "                config.svg.append(\"text\")\n",
              "                    .text(config.heads[i])\n",
              "                    .attr(\"fill\", \"black\")\n",
              "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                    .attr(\"x\", axisSize + (i + .5) * config.thumbnailWidth)\n",
              "                    .attr(\"text-anchor\", \"middle\")\n",
              "                    .attr(\"y\", HEADING_TEXT_SIZE + HEADING_PADDING)\n",
              "                    .attr(\"dy\", TEXT_SIZE);\n",
              "            }\n",
              "            let x = 0;\n",
              "            let y = axisSize + config.thumbnailHeight * config.layers.length / 2;\n",
              "            console.log(\"x\", x, y)\n",
              "            config.svg.append(\"text\")\n",
              "                .text(\"Layers\")\n",
              "                .attr(\"fill\", \"black\")\n",
              "                .attr(\"font-weight\", \"bold\")\n",
              "                .attr(\"transform\", \"rotate(270, \" + x  + \", \" + y + \")\")\n",
              "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"text-anchor\", \"middle\")\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
              "            for (let i = 0; i < config.numLayers; i++) {\n",
              "                x = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE; // HACK\n",
              "                y = axisSize + (i + .5) * config.thumbnailHeight;\n",
              "                config.svg.append(\"text\")\n",
              "                    .text(config.layers[i])\n",
              "                    .attr(\"fill\", \"black\")\n",
              "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                    .attr(\"x\", x)\n",
              "                    .attr(\"text-anchor\", \"end\")\n",
              "                    .attr(\"y\", y)\n",
              "                    .attr(\"dy\", TEXT_SIZE / 2);\n",
              "            }\n",
              "        }\n",
              "\n",
              "\n",
              "        function renderThumbnail(layerIndex, headIndex) {\n",
              "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING\n",
              "            const x = headIndex * config.thumbnailWidth + axisSize;\n",
              "            const y = layerIndex * config.thumbnailHeight + axisSize;\n",
              "            renderThumbnailAttn(x, y, config.attn[layerIndex][headIndex], layerIndex, headIndex);\n",
              "        }\n",
              "\n",
              "        function renderDetail(att, layerIndex, headIndex) {\n",
              "            const axisSize = TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
              "            var xOffset = .8 * config.thumbnailWidth;\n",
              "            var maxX = DIV_WIDTH;\n",
              "            var maxY = config.divHeight - 3;\n",
              "            var leftPos = axisSize + headIndex * config.thumbnailWidth;\n",
              "            var x = leftPos + THUMBNAIL_PADDING + xOffset;\n",
              "            if (x < MIN_X) {\n",
              "                x = MIN_X;\n",
              "            } else if (x + DETAIL_WIDTH > maxX) {\n",
              "                x = leftPos + THUMBNAIL_PADDING - DETAIL_WIDTH + 8;\n",
              "            }\n",
              "            var posLeftText = x;\n",
              "            var posAttention = posLeftText + DETAIL_BOX_WIDTH;\n",
              "            var posRightText = posAttention + DETAIL_ATTENTION_WIDTH;\n",
              "            var thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
              "            var yOffset = 20;\n",
              "            var y = layerIndex * thumbnailHeight + THUMBNAIL_PADDING + yOffset;\n",
              "            if (y < MIN_Y) {\n",
              "                y = MIN_Y;\n",
              "            } else if (y + config.detailHeight > maxY) {\n",
              "                y = maxY - config.detailHeight;\n",
              "            }\n",
              "            renderDetailFrame(x, y, layerIndex);\n",
              "            y = y + DETAIL_PADDING;\n",
              "            renderDetailHeading(x, y, layerIndex, headIndex);\n",
              "            y = y + DETAIL_HEADING_HEIGHT;\n",
              "            renderDetailText(config.leftText, \"leftText\", posLeftText, y , layerIndex);\n",
              "            renderDetailAttn(posAttention, y, att, layerIndex, headIndex);\n",
              "            renderDetailText(config.rightText, \"rightText\", posRightText, y, layerIndex);\n",
              "        }\n",
              "\n",
              "        function renderDetailHeading(x, y, layerIndex, headIndex) {\n",
              "            var fillColor = getTextColor();\n",
              "            config.svg.append(\"text\")\n",
              "                .classed(\"detail\", true)\n",
              "                .text('Layer ' + config.layers[layerIndex] + \", Head \" + config.heads[headIndex])\n",
              "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                .attr(\"font-weight\", \"bold\")\n",
              "                .style(\"cursor\", \"default\")\n",
              "                .style(\"-webkit-user-select\", \"none\")\n",
              "                .attr(\"fill\", fillColor)\n",
              "                .attr(\"x\", x + DETAIL_WIDTH / 2)\n",
              "                .attr(\"text-anchor\", \"middle\")\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", DETAIL_HEADING_HEIGHT)\n",
              "                .attr(\"width\", DETAIL_WIDTH)\n",
              "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
              "        }\n",
              "\n",
              "        function renderDetailText(text, id, x, y, layerIndex) {\n",
              "            var tokenContainer = config.svg.append(\"svg:g\")\n",
              "                .classed(\"detail\", true)\n",
              "                .selectAll(\"g\")\n",
              "                .data(text)\n",
              "                .enter()\n",
              "                .append(\"g\");\n",
              "\n",
              "            var fillColor = getTextColor();\n",
              "\n",
              "            tokenContainer.append(\"rect\")\n",
              "                .classed(\"highlight\", true)\n",
              "                .attr(\"fill\", fillColor)\n",
              "                .style(\"opacity\", 0.0)\n",
              "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
              "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", function (d, i) {\n",
              "                    return y + i * DETAIL_BOX_HEIGHT;\n",
              "                });\n",
              "\n",
              "            var textContainer = tokenContainer.append(\"text\")\n",
              "                .classed(\"token\", true)\n",
              "                .text(function (d) {\n",
              "                    return d;\n",
              "                })\n",
              "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                .style(\"cursor\", \"default\")\n",
              "                .style(\"-webkit-user-select\", \"none\")\n",
              "                .attr(\"fill\", fillColor)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", function (d, i) {\n",
              "                    return i * DETAIL_BOX_HEIGHT + y;\n",
              "                })\n",
              "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
              "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "\n",
              "            if (id == \"leftText\") {\n",
              "                textContainer.style(\"text-anchor\", \"end\")\n",
              "                    .attr(\"dx\", DETAIL_BOX_WIDTH - 2);\n",
              "                tokenContainer.on(\"mouseover\", function (d, index) {\n",
              "                    highlightSelection(index);\n",
              "                });\n",
              "                tokenContainer.on(\"mouseleave\", function () {\n",
              "                    unhighlightSelection();\n",
              "                });\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function highlightSelection(index) {\n",
              "            config.svg.select(\"#leftText\")\n",
              "                .selectAll(\".highlight\")\n",
              "                .style(\"opacity\", function (d, i) {\n",
              "                    return i == index ? 1.0 : 0.0;\n",
              "                });\n",
              "            config.svg.selectAll(\".attn-line-group\")\n",
              "                .style(\"opacity\", function (d, i) {\n",
              "                    return i == index ? 1.0 : 0.0;\n",
              "                });\n",
              "        }\n",
              "\n",
              "        function unhighlightSelection() {\n",
              "            config.svg.select(\"#leftText\")\n",
              "                .selectAll(\".highlight\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "            config.svg.selectAll(\".attn-line-group\")\n",
              "                .style(\"opacity\", 1);\n",
              "        }\n",
              "\n",
              "        function renderThumbnailAttn(x, y, att, layerIndex, headIndex) {\n",
              "\n",
              "            var attnContainer = config.svg.append(\"svg:g\");\n",
              "\n",
              "            var attnBackground = attnContainer.append(\"rect\")\n",
              "                .attr(\"id\", 'attn_background_' + layerIndex + \"_\" + headIndex)\n",
              "                .classed(\"attn_background\", true)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", config.thumbnailHeight)\n",
              "                .attr(\"width\", config.thumbnailWidth)\n",
              "                .attr(\"stroke-width\", 2)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
              "                .attr(\"stroke-opacity\", 0)\n",
              "                .attr(\"fill\", getBackgroundColor());\n",
              "            var x1 = x + THUMBNAIL_PADDING;\n",
              "            var x2 = x1 + config.thumbnailWidth - 14;\n",
              "            var y1 = y + THUMBNAIL_PADDING;\n",
              "\n",
              "            attnContainer.selectAll(\"g\")\n",
              "                .data(att)\n",
              "                .enter()\n",
              "                .append(\"g\") // Add group for each source token\n",
              "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
              "                    return i;\n",
              "                })\n",
              "                .selectAll(\"line\")\n",
              "                .data(function (d) { // Loop over all target tokens\n",
              "                    return d;\n",
              "                })\n",
              "                .enter() // When entering\n",
              "                .append(\"line\")\n",
              "                .attr(\"x1\", x1)\n",
              "                .attr(\"y1\", function (d) {\n",
              "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
              "                    return y1 + (sourceIndex + .5) * config.thumbnailBoxHeight;\n",
              "                })\n",
              "                .attr(\"x2\", x2)\n",
              "                .attr(\"y2\", function (d, targetIndex) {\n",
              "                    return y1 + (targetIndex + .5) * config.thumbnailBoxHeight;\n",
              "                })\n",
              "                .attr(\"stroke-width\", 2.2)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
              "                .attr(\"stroke-opacity\", function (d) {\n",
              "                    return d;\n",
              "                });\n",
              "\n",
              "            var clickRegion = attnContainer.append(\"rect\")\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", config.thumbnailHeight)\n",
              "                .attr(\"width\", config.thumbnailWidth)\n",
              "                .style(\"opacity\", 0);\n",
              "\n",
              "            clickRegion.on(\"click\", function (d, index) {\n",
              "                var attnBackgroundOther = config.svg.selectAll(\".attn_background\");\n",
              "                attnBackgroundOther.attr(\"fill\", getBackgroundColor());\n",
              "                attnBackgroundOther.attr(\"stroke-opacity\", 0);\n",
              "\n",
              "                config.svg.selectAll(\".detail\").remove();\n",
              "                if (config.detail_layer != layerIndex || config.detail_head != headIndex) {\n",
              "                    renderDetail(att, layerIndex, headIndex);\n",
              "                    config.detail_layer = layerIndex;\n",
              "                    config.detail_head = headIndex;\n",
              "                    attnBackground.attr(\"fill\", getHighlightColor());\n",
              "                    attnBackground.attr(\"stroke-opacity\", .8);\n",
              "                } else {\n",
              "                    config.detail_layer = null;\n",
              "                    config.detail_head = null;\n",
              "                    attnBackground.attr(\"fill\", getBackgroundColor());\n",
              "                    attnBackground.attr(\"stroke-opacity\", 0);\n",
              "                }\n",
              "            });\n",
              "\n",
              "            clickRegion.on(\"mouseover\", function (d) {\n",
              "                d3.select(this).style(\"cursor\", \"pointer\");\n",
              "            });\n",
              "        }\n",
              "\n",
              "        function renderDetailFrame(x, y, layerIndex) {\n",
              "            var detailFrame = config.svg.append(\"rect\")\n",
              "                .classed(\"detail\", true)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", config.detailHeight)\n",
              "                .attr(\"width\", DETAIL_WIDTH)\n",
              "                .style(\"opacity\", 1)\n",
              "                .attr(\"stroke-width\", 1.5)\n",
              "                .attr(\"stroke-opacity\", 0.7)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex));\n",
              "        }\n",
              "\n",
              "        function renderDetailAttn(x, y, att, layerIndex) {\n",
              "            var attnContainer = config.svg.append(\"svg:g\")\n",
              "                .classed(\"detail\", true)\n",
              "                .attr(\"pointer-events\", \"none\");\n",
              "            attnContainer.selectAll(\"g\")\n",
              "                .data(att)\n",
              "                .enter()\n",
              "                .append(\"g\") // Add group for each source token\n",
              "                .classed('attn-line-group', true)\n",
              "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
              "                    return i;\n",
              "                })\n",
              "                .selectAll(\"line\")\n",
              "                .data(function (d) { // Loop over all target tokens\n",
              "                    return d;\n",
              "                })\n",
              "                .enter()\n",
              "                .append(\"line\")\n",
              "                .attr(\"x1\", x + ATTN_PADDING)\n",
              "                .attr(\"y1\", function (d) {\n",
              "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
              "                    return y + (sourceIndex + .5) * DETAIL_BOX_HEIGHT;\n",
              "                })\n",
              "                .attr(\"x2\", x + DETAIL_ATTENTION_WIDTH - ATTN_PADDING)\n",
              "                .attr(\"y2\", function (d, targetIndex) {\n",
              "                    return y + (targetIndex + .5) * DETAIL_BOX_HEIGHT;\n",
              "                })\n",
              "                .attr(\"stroke-width\", 2.2)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
              "                .attr(\"stroke-opacity\", function (d) {\n",
              "                    return d;\n",
              "                });\n",
              "        }\n",
              "\n",
              "        function getLayerColor(layer) {\n",
              "          return LAYER_COLORS[config.layers[layer] % 10];\n",
              "        }\n",
              "\n",
              "        function getTextColor() {\n",
              "            return PALETTE[config.mode]['text']\n",
              "        }\n",
              "\n",
              "        function getBackgroundColor() {\n",
              "           return PALETTE[config.mode]['background']\n",
              "        }\n",
              "\n",
              "        function getHighlightColor() {\n",
              "           return PALETTE[config.mode]['highlight']\n",
              "        }\n",
              "\n",
              "        function initialize() {\n",
              "            config.attention = params['attention'];\n",
              "            config.filter = params['default_filter'];\n",
              "            config.mode = params['display_mode'];\n",
              "            config.layers = params['include_layers']\n",
              "            config.heads = params['include_heads']\n",
              "            config.totalHeads = params['total_heads']\n",
              "            config.rootDivId = params['root_div_id'];\n",
              "            $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
              "                config.filter = e.currentTarget.value;\n",
              "                render();\n",
              "            });\n",
              "        }\n",
              "\n",
              "        initialize();\n",
              "        render();\n",
              "\n",
              "    });"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "      \n",
              "        <div id=\"bertviz-e8aa6a3187984757a6f5c190e674c76a\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
              "            <span style=\"user-select:none\">\n",
              "                Layer: <select id=\"layer\"></select>\n",
              "                \n",
              "            </span>\n",
              "            <div id='vis'></div>\n",
              "        </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/**\n",
              " * @fileoverview Transformer Visualization D3 javascript code.\n",
              " *\n",
              " *\n",
              " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
              " *\n",
              " * Change log:\n",
              " *\n",
              " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
              " * 12/29/20  Jesse Vig   Significant refactor.\n",
              " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
              " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
              " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
              " * 07/25/21  Jesse Vig   Support layer filtering\n",
              " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
              " **/\n",
              "\n",
              "require.config({\n",
              "  paths: {\n",
              "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
              "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "  }\n",
              "});\n",
              "\n",
              "requirejs(['jquery', 'd3'], function ($, d3) {\n",
              "\n",
              "    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[0.10261322557926178, 0.09967197477817535, 0.10471662878990173, 0.1038997694849968, 0.09983649104833603, 0.10672742128372192, 0.0, 0.09467925876379013, 0.1027178093791008, 0.09467300027608871, 0.10089392215013504], [0.10247872024774551, 0.09869556874036789, 0.10005058348178864, 0.1000746414065361, 0.1023896262049675, 0.10857154428958893, 0.1015227735042572, 0.09821164608001709, 0.10331778228282928, 0.0, 0.10330332815647125], [0.10497140884399414, 0.09207195788621902, 0.10707926005125046, 0.10070165991783142, 0.09988104552030563, 0.10489410161972046, 0.1053796112537384, 0.10011020302772522, 0.0, 0.0, 0.10006213188171387], [0.10361217707395554, 0.09122499823570251, 0.10280917584896088, 0.0, 0.09795103222131729, 0.10856793075799942, 0.10424041002988815, 0.09782327711582184, 0.10496597737073898, 0.09661659598350525, 0.099065400660038], [0.10492746531963348, 0.0982961356639862, 0.10253798216581345, 0.09748247265815735, 0.10278459638357162, 0.11140727251768112, 0.09786141663789749, 0.09840285032987595, 0.10260577499866486, 0.09170247614383698, 0.10310272872447968], [0.10093294084072113, 0.09938225895166397, 0.10557500272989273, 0.10064313560724258, 0.09358999878168106, 0.10638077557086945, 0.10733737051486969, 0.09995315968990326, 0.10161001235246658, 0.09176583588123322, 0.10394064337015152], [0.10046476125717163, 0.102973073720932, 0.10734346508979797, 0.09853053092956543, 0.0, 0.1072402372956276, 0.10158418118953705, 0.09359680861234665, 0.10474615544080734, 0.0979078859090805, 0.09786723554134369], [0.0, 0.09739644825458527, 0.10495445132255554, 0.0, 0.09758955240249634, 0.10278721898794174, 0.10292214155197144, 0.10269981622695923, 0.10587749630212784, 0.09299605339765549, 0.10312676429748535], [0.1027401015162468, 0.09552285820245743, 0.0, 0.0, 0.10002180933952332, 0.10706166923046112, 0.10142338275909424, 0.09799839556217194, 0.10051031410694122, 0.0957753136754036, 0.0], [0.1060720831155777, 0.09403406828641891, 0.0, 0.10006547719240189, 0.09810510277748108, 0.0, 0.10388315469026566, 0.10272551327943802, 0.10464261472225189, 0.0, 0.0], [0.1048453152179718, 0.09689179062843323, 0.0, 0.0, 0.09987125545740128, 0.10310930013656616, 0.10007871687412262, 0.09463348239660263, 0.10000962764024734, 0.09472097456455231, 0.10277771204710007]], [[0.10659626126289368, 0.10302228480577469, 0.09231570363044739, 0.09828221052885056, 0.10136548429727554, 0.09572184085845947, 0.0, 0.10417351126670837, 0.10217519849538803, 0.1066778153181076, 0.09559626132249832], [0.11260632425546646, 0.09987540543079376, 0.0, 0.09728659689426422, 0.09980254620313644, 0.09590300172567368, 0.11148575693368912, 0.0982823446393013, 0.09597833454608917, 0.0, 0.0], [0.10548647493124008, 0.10244583338499069, 0.10199815779924393, 0.10069859772920609, 0.0986950695514679, 0.0, 0.10699962824583054, 0.10394635796546936, 0.0974501296877861, 0.10350039601325989, 0.09200325608253479], [0.10253225266933441, 0.10279836505651474, 0.09838297963142395, 0.09929431229829788, 0.10263563692569733, 0.09716803580522537, 0.1071256771683693, 0.1032525897026062, 0.09979013353586197, 0.10350768268108368, 0.09462352842092514], [0.10690803825855255, 0.10128505527973175, 0.09791620075702667, 0.09565020352602005, 0.0, 0.0960053876042366, 0.10773812979459763, 0.0, 0.09639480710029602, 0.10870788246393204, 0.09311983734369278], [0.11030584573745728, 0.10108793526887894, 0.09638321399688721, 0.0, 0.10094886273145676, 0.09588728100061417, 0.1076977401971817, 0.09985519200563431, 0.0, 0.10940790921449661, 0.0930757150053978], [0.11019891500473022, 0.09928234666585922, 0.10202187299728394, 0.09843119233846664, 0.09479568898677826, 0.09477296471595764, 0.10866666585206985, 0.09921565651893616, 0.10064657777547836, 0.10790647566318512, 0.09517276287078857], [0.10522309690713882, 0.10367660224437714, 0.10252387821674347, 0.09481199830770493, 0.09825848788022995, 0.09678053855895996, 0.11233675479888916, 0.10498469322919846, 0.09429491311311722, 0.10068397223949432, 0.09753623604774475], [0.11126106977462769, 0.09581680595874786, 0.09803549945354462, 0.09711182117462158, 0.10118633508682251, 0.09841529279947281, 0.0, 0.09768938273191452, 0.09782659262418747, 0.1039622500538826, 0.100148506462574], [0.10366137325763702, 0.09677073359489441, 0.09804036468267441, 0.10082593560218811, 0.09918923676013947, 0.09725736826658249, 0.10854025930166245, 0.10118505358695984, 0.10165293514728546, 0.10427587479352951, 0.0], [0.10552319884300232, 0.0969487875699997, 0.10170379281044006, 0.10286693274974823, 0.09721381962299347, 0.09676181524991989, 0.10214473307132721, 0.0, 0.10059055685997009, 0.10736937075853348, 0.09994251281023026]]]], \"left_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"], \"right_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-e8aa6a3187984757a6f5c190e674c76a\", \"layer\": null, \"heads\": null, \"include_layers\": [0]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[0.10261322557926178, 0.09967197477817535, 0.10471662878990173, 0.1038997694849968, 0.09983649104833603, 0.10672742128372192, 0.0, 0.09467925876379013, 0.1027178093791008, 0.09467300027608871, 0.10089392215013504], [0.10247872024774551, 0.09869556874036789, 0.10005058348178864, 0.1000746414065361, 0.1023896262049675, 0.10857154428958893, 0.1015227735042572, 0.09821164608001709, 0.10331778228282928, 0.0, 0.10330332815647125], [0.10497140884399414, 0.09207195788621902, 0.10707926005125046, 0.10070165991783142, 0.09988104552030563, 0.10489410161972046, 0.1053796112537384, 0.10011020302772522, 0.0, 0.0, 0.10006213188171387], [0.10361217707395554, 0.09122499823570251, 0.10280917584896088, 0.0, 0.09795103222131729, 0.10856793075799942, 0.10424041002988815, 0.09782327711582184, 0.10496597737073898, 0.09661659598350525, 0.099065400660038], [0.10492746531963348, 0.0982961356639862, 0.10253798216581345, 0.09748247265815735, 0.10278459638357162, 0.11140727251768112, 0.09786141663789749, 0.09840285032987595, 0.10260577499866486, 0.09170247614383698, 0.10310272872447968], [0.10093294084072113, 0.09938225895166397, 0.10557500272989273, 0.10064313560724258, 0.09358999878168106, 0.10638077557086945, 0.10733737051486969, 0.09995315968990326, 0.10161001235246658, 0.09176583588123322, 0.10394064337015152], [0.10046476125717163, 0.102973073720932, 0.10734346508979797, 0.09853053092956543, 0.0, 0.1072402372956276, 0.10158418118953705, 0.09359680861234665, 0.10474615544080734, 0.0979078859090805, 0.09786723554134369], [0.0, 0.09739644825458527, 0.10495445132255554, 0.0, 0.09758955240249634, 0.10278721898794174, 0.10292214155197144, 0.10269981622695923, 0.10587749630212784, 0.09299605339765549, 0.10312676429748535], [0.1027401015162468, 0.09552285820245743, 0.0, 0.0, 0.10002180933952332, 0.10706166923046112, 0.10142338275909424, 0.09799839556217194, 0.10051031410694122, 0.0957753136754036, 0.0], [0.1060720831155777, 0.09403406828641891, 0.0, 0.10006547719240189, 0.09810510277748108, 0.0, 0.10388315469026566, 0.10272551327943802, 0.10464261472225189, 0.0, 0.0], [0.1048453152179718, 0.09689179062843323, 0.0, 0.0, 0.09987125545740128, 0.10310930013656616, 0.10007871687412262, 0.09463348239660263, 0.10000962764024734, 0.09472097456455231, 0.10277771204710007]], [[0.10659626126289368, 0.10302228480577469, 0.09231570363044739, 0.09828221052885056, 0.10136548429727554, 0.09572184085845947, 0.0, 0.10417351126670837, 0.10217519849538803, 0.1066778153181076, 0.09559626132249832], [0.11260632425546646, 0.09987540543079376, 0.0, 0.09728659689426422, 0.09980254620313644, 0.09590300172567368, 0.11148575693368912, 0.0982823446393013, 0.09597833454608917, 0.0, 0.0], [0.10548647493124008, 0.10244583338499069, 0.10199815779924393, 0.10069859772920609, 0.0986950695514679, 0.0, 0.10699962824583054, 0.10394635796546936, 0.0974501296877861, 0.10350039601325989, 0.09200325608253479], [0.10253225266933441, 0.10279836505651474, 0.09838297963142395, 0.09929431229829788, 0.10263563692569733, 0.09716803580522537, 0.1071256771683693, 0.1032525897026062, 0.09979013353586197, 0.10350768268108368, 0.09462352842092514], [0.10690803825855255, 0.10128505527973175, 0.09791620075702667, 0.09565020352602005, 0.0, 0.0960053876042366, 0.10773812979459763, 0.0, 0.09639480710029602, 0.10870788246393204, 0.09311983734369278], [0.11030584573745728, 0.10108793526887894, 0.09638321399688721, 0.0, 0.10094886273145676, 0.09588728100061417, 0.1076977401971817, 0.09985519200563431, 0.0, 0.10940790921449661, 0.0930757150053978], [0.11019891500473022, 0.09928234666585922, 0.10202187299728394, 0.09843119233846664, 0.09479568898677826, 0.09477296471595764, 0.10866666585206985, 0.09921565651893616, 0.10064657777547836, 0.10790647566318512, 0.09517276287078857], [0.10522309690713882, 0.10367660224437714, 0.10252387821674347, 0.09481199830770493, 0.09825848788022995, 0.09678053855895996, 0.11233675479888916, 0.10498469322919846, 0.09429491311311722, 0.10068397223949432, 0.09753623604774475], [0.11126106977462769, 0.09581680595874786, 0.09803549945354462, 0.09711182117462158, 0.10118633508682251, 0.09841529279947281, 0.0, 0.09768938273191452, 0.09782659262418747, 0.1039622500538826, 0.100148506462574], [0.10366137325763702, 0.09677073359489441, 0.09804036468267441, 0.10082593560218811, 0.09918923676013947, 0.09725736826658249, 0.10854025930166245, 0.10118505358695984, 0.10165293514728546, 0.10427587479352951, 0.0], [0.10552319884300232, 0.0969487875699997, 0.10170379281044006, 0.10286693274974823, 0.09721381962299347, 0.09676181524991989, 0.10214473307132721, 0.0, 0.10059055685997009, 0.10736937075853348, 0.09994251281023026]]]], \"left_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"], \"right_text\": [\"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\", \"Hello\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-e8aa6a3187984757a6f5c190e674c76a\", \"layer\": null, \"heads\": null, \"include_layers\": [0]} is a template marker that is replaced by actual params.\n",
              "    const TEXT_SIZE = 15;\n",
              "    const BOXWIDTH = 110;\n",
              "    const BOXHEIGHT = 22.5;\n",
              "    const MATRIX_WIDTH = 115;\n",
              "    const CHECKBOX_SIZE = 20;\n",
              "    const TEXT_TOP = 30;\n",
              "\n",
              "    console.log(\"d3 version\", d3.version)\n",
              "    let headColors;\n",
              "    try {\n",
              "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
              "    } catch (err) {\n",
              "        console.log('Older d3 version')\n",
              "        headColors = d3.scale.category10();\n",
              "    }\n",
              "    let config = {};\n",
              "    initialize();\n",
              "    renderVis();\n",
              "\n",
              "    function initialize() {\n",
              "        config.attention = params['attention'];\n",
              "        config.filter = params['default_filter'];\n",
              "        config.rootDivId = params['root_div_id'];\n",
              "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
              "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
              "        config.layers = params['include_layers']\n",
              "\n",
              "        if (params['heads']) {\n",
              "            config.headVis = new Array(config.nHeads).fill(false);\n",
              "            params['heads'].forEach(x => config.headVis[x] = true);\n",
              "        } else {\n",
              "            config.headVis = new Array(config.nHeads).fill(true);\n",
              "        }\n",
              "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
              "        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n",
              "        config.layer = config.layers[config.layer_seq]\n",
              "\n",
              "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
              "        for (const layer of config.layers) {\n",
              "            layerEl.append($(\"<option />\").val(layer).text(layer));\n",
              "        }\n",
              "        layerEl.val(config.layer).change();\n",
              "        layerEl.on('change', function (e) {\n",
              "            config.layer = +e.currentTarget.value;\n",
              "            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n",
              "            renderVis();\n",
              "        });\n",
              "\n",
              "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
              "            config.filter = e.currentTarget.value;\n",
              "            renderVis();\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderVis() {\n",
              "\n",
              "        // Load parameters\n",
              "        const attnData = config.attention[config.filter];\n",
              "        const leftText = attnData.left_text;\n",
              "        const rightText = attnData.right_text;\n",
              "\n",
              "        // Select attention for given layer\n",
              "        const layerAttention = attnData.attn[config.layer_seq];\n",
              "\n",
              "        // Clear vis\n",
              "        $(`#${config.rootDivId} #vis`).empty();\n",
              "\n",
              "        // Determine size of visualization\n",
              "        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n",
              "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
              "            .append('svg')\n",
              "            .attr(\"width\", \"100%\")\n",
              "            .attr(\"height\", height + \"px\");\n",
              "\n",
              "        // Display tokens on left and right side of visualization\n",
              "        renderText(svg, leftText, true, layerAttention, 0);\n",
              "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
              "\n",
              "        // Render attention arcs\n",
              "        renderAttention(svg, layerAttention);\n",
              "\n",
              "        // Draw squares at top of visualization, one for each head\n",
              "        drawCheckboxes(0, svg, layerAttention);\n",
              "    }\n",
              "\n",
              "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
              "\n",
              "        const textContainer = svg.append(\"svg:g\")\n",
              "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
              "\n",
              "        // Add attention highlights superimposed over words\n",
              "        textContainer.append(\"g\")\n",
              "            .classed(\"attentionBoxes\", true)\n",
              "            .selectAll(\"g\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\"rect\")\n",
              "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"x\", function () {\n",
              "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                return leftPos + boxOffsets(headIndex);\n",
              "            })\n",
              "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "            .attr(\"height\", BOXHEIGHT)\n",
              "            .attr(\"fill\", function () {\n",
              "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
              "            })\n",
              "            .style(\"opacity\", 0.0);\n",
              "\n",
              "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
              "            .data(text)\n",
              "            .enter()\n",
              "            .append(\"g\");\n",
              "\n",
              "        // Add gray background that appears when hovering over text\n",
              "        tokenContainer.append(\"rect\")\n",
              "            .classed(\"background\", true)\n",
              "            .style(\"opacity\", 0.0)\n",
              "            .attr(\"fill\", \"lightgray\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH)\n",
              "            .attr(\"height\", BOXHEIGHT);\n",
              "\n",
              "        // Add token text\n",
              "        const textEl = tokenContainer.append(\"text\")\n",
              "            .text(d => d)\n",
              "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "            .style(\"cursor\", \"default\")\n",
              "            .style(\"-webkit-user-select\", \"none\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
              "\n",
              "        if (isLeft) {\n",
              "            textEl.style(\"text-anchor\", \"end\")\n",
              "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        } else {\n",
              "            textEl.style(\"text-anchor\", \"start\")\n",
              "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        }\n",
              "\n",
              "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
              "\n",
              "            // Show gray background for moused-over token\n",
              "            textContainer.selectAll(\".background\")\n",
              "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
              "\n",
              "            // Reset visibility attribute for any previously highlighted attention arcs\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null)\n",
              "\n",
              "            // Hide group containing attention arcs\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
              "\n",
              "            // Set to visible appropriate attention arcs to be highlighted\n",
              "            if (isLeft) {\n",
              "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            } else {\n",
              "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            }\n",
              "\n",
              "            // Update color boxes superimposed over tokens\n",
              "            const id = isLeft ? \"right\" : \"left\";\n",
              "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
              "            svg.select(\"#\" + id)\n",
              "                .selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .attr(\"head-index\", (d, i) => i)\n",
              "                .selectAll(\"rect\")\n",
              "                .attr(\"x\", function () {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    return leftPos + boxOffsets(headIndex);\n",
              "                })\n",
              "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "                .attr(\"height\", BOXHEIGHT)\n",
              "                .style(\"opacity\", function (d) {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    if (config.headVis[headIndex])\n",
              "                        if (d) {\n",
              "                            return d[index];\n",
              "                        } else {\n",
              "                            return 0.0;\n",
              "                        }\n",
              "                    else\n",
              "                        return 0.0;\n",
              "                });\n",
              "        });\n",
              "\n",
              "        textContainer.on(\"mouseleave\", function () {\n",
              "\n",
              "            // Unhighlight selected token\n",
              "            d3.select(this).selectAll(\".background\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "\n",
              "            // Reset visibility attributes for previously selected lines\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null) ;\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
              "\n",
              "            // Reset highlights superimposed over tokens\n",
              "            svg.selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .selectAll(\"rect\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderAttention(svg, attention) {\n",
              "\n",
              "        // Remove previous dom elements\n",
              "        svg.select(\"#attention\").remove();\n",
              "\n",
              "        // Add new elements\n",
              "        svg.append(\"g\")\n",
              "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
              "            .selectAll(\".headAttention\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\".tokenAttention\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
              "            .attr(\"left-token-index\", (d, i) => i)\n",
              "            .selectAll(\"line\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"line\")\n",
              "            .attr(\"x1\", BOXWIDTH)\n",
              "            .attr(\"y1\", function () {\n",
              "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
              "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
              "            })\n",
              "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
              "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
              "            .attr(\"stroke-width\", 2)\n",
              "            .attr(\"stroke\", function () {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                return headColors(headIndex)\n",
              "            })\n",
              "            .attr(\"left-token-index\", function () {\n",
              "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
              "            })\n",
              "            .attr(\"right-token-index\", (d, i) => i)\n",
              "        ;\n",
              "        updateAttention(svg)\n",
              "    }\n",
              "\n",
              "    function updateAttention(svg) {\n",
              "        svg.select(\"#attention\")\n",
              "            .selectAll(\"line\")\n",
              "            .attr(\"stroke-opacity\", function (d) {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                // If head is selected\n",
              "                if (config.headVis[headIndex]) {\n",
              "                    // Set opacity to attention weight divided by number of active heads\n",
              "                    return d / activeHeads()\n",
              "                } else {\n",
              "                    return 0.0;\n",
              "                }\n",
              "            })\n",
              "    }\n",
              "\n",
              "    function boxOffsets(i) {\n",
              "        const numHeadsAbove = config.headVis.reduce(\n",
              "            function (acc, val, cur) {\n",
              "                return val && cur < i ? acc + 1 : acc;\n",
              "            }, 0);\n",
              "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
              "    }\n",
              "\n",
              "    function activeHeads() {\n",
              "        return config.headVis.reduce(function (acc, val) {\n",
              "            return val ? acc + 1 : acc;\n",
              "        }, 0);\n",
              "    }\n",
              "\n",
              "    function drawCheckboxes(top, svg) {\n",
              "        const checkboxContainer = svg.append(\"g\");\n",
              "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
              "            .data(config.headVis)\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"fill\", (d, i) => headColors(i))\n",
              "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
              "            .attr(\"y\", top)\n",
              "            .attr(\"width\", CHECKBOX_SIZE)\n",
              "            .attr(\"height\", CHECKBOX_SIZE);\n",
              "\n",
              "        function updateCheckboxes() {\n",
              "            checkboxContainer.selectAll(\"rect\")\n",
              "                .data(config.headVis)\n",
              "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
              "        }\n",
              "\n",
              "        updateCheckboxes();\n",
              "\n",
              "        checkbox.on(\"click\", function (d, i) {\n",
              "            if (config.headVis[i] && activeHeads() === 1) return;\n",
              "            config.headVis[i] = !config.headVis[i];\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "\n",
              "        checkbox.on(\"dblclick\", function (d, i) {\n",
              "            // If we double click on the only active head then reset\n",
              "            if (config.headVis[i] && activeHeads() === 1) {\n",
              "                config.headVis = new Array(config.nHeads).fill(true);\n",
              "            } else {\n",
              "                config.headVis = new Array(config.nHeads).fill(false);\n",
              "                config.headVis[i] = true;\n",
              "            }\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function lighten(color) {\n",
              "        const c = d3.hsl(color);\n",
              "        const increment = (1 - c.l) * 0.6;\n",
              "        c.l += increment;\n",
              "        c.s -= increment;\n",
              "        return c;\n",
              "    }\n",
              "\n",
              "    function transpose(mat) {\n",
              "        return mat[0].map(function (col, i) {\n",
              "            return mat.map(function (row) {\n",
              "                return row[i];\n",
              "            });\n",
              "        });\n",
              "    }\n",
              "\n",
              "});"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "bertviz_attention_weight = (attn_weights[0].unsqueeze(0), ) # for 1st sequence\n",
        "bertviz_token_string = [\"Hello\"] * 11\n",
        "print(f\"attentions: {len(bertviz_attention_weight)} encoder layers, each with an attention matrix of shape {bertviz_attention_weight[0].shape}\")\n",
        "bertviz.model_view(bertviz_attention_weight, bertviz_token_string)\n",
        "bertviz.head_view(bertviz_attention_weight, bertviz_token_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7wYq-oAAtSC"
      },
      "source": [
        "However, in a decoder model (unlike an encoder), tokens should only attend to past tokens (those that come earlier in the sequence). To achieve it, we will implement a masking mechanism on the attention scores, so that only past tokens are considered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtMc68Z9AtSC"
      },
      "source": [
        "For simplicity and illustration purpose, we generate a random attention score matrix of size [1, 1, num_tokens, num_tokens] with the [torch.rand](https://pytorch.org/docs/main/generated/torch.rand.html) function, representing the attention scores for a single sequence and a single attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxRWjowFAtSD"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "num_tokens = 6\n",
        "attn_scores = torch.rand(1, 1, num_tokens, num_tokens)   # done by me\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJcGXEr5AtSD"
      },
      "source": [
        "As the first step in creating our mask, we use the [torch.ones](https://pytorch.org/docs/main/generated/torch.ones.html) function to generate a matrix of ones with a size of [num_tokens, num_tokens]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIa270xdEl0a"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "matrix_ones = ...\n",
        "print(matrix_ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdGlKNYiAtSD"
      },
      "source": [
        "Next, we apply the [torch.triu](https://pytorch.org/docs/stable/generated/torch.triu.html) function on our matrix of ones to set the lower triangular part—including the main diagonal—to zeros while keeping the ones in the upper triangular part. Use the \"diagonal\" parameter of this function to ensure that the main diagonal is also set to zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0zs0JpLEu5a"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "mask_int = ...\n",
        "print(mask_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20zCg4RQAtSD"
      },
      "source": [
        "Then, based on our mask tensor of ones and zeros, we generate a boolean mask with True and False values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEACuj4eAtSD"
      },
      "outputs": [],
      "source": [
        "mask_bool = mask_int.bool()\n",
        "print(mask_bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbOp81x9AtSD"
      },
      "source": [
        "Next, we mask the upper triangular part of the attention score matrix by replacing these values by \"negative infinity\" (using -torch.inf). To do this, we apply the [masked_fill](https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill.html) function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ck2ZlBHE6LU"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "attn_masked = ...\n",
        "print(attn_masked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RZbrpInAtSE"
      },
      "source": [
        "When we apply the softmax function to this masked attention score matrix, the -inf values become zeros, and each row sums up to 1. Since a token's contextualized embedding is computed as a weighted average of other token embeddings (using the attention weights), the future tokens will have a weight of zero. This means that a given token's embedding will not incorporate information from future tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyVSo4R5AtSE"
      },
      "outputs": [],
      "source": [
        "attn_weights = torch.softmax(attn_masked, dim=-1) # note that in the multi head implemention, a scaling factor would have been applied on the masked attention scores.\n",
        "print(attn_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTryt5dQAtSE"
      },
      "source": [
        "Reusing our implementation of the mask, you can now code our decoder's CausalMultiHeadAttention class that masks future tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CDgZ51BFIKR"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "class CausalMultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, dropout, num_heads, qkv_bias=False, output_attention_weights = True):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "        self.output_attention_weights = output_attention_weights\n",
        "\n",
        "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x): # embeddings (batch_size, num_tokens, d_in)\n",
        "\n",
        "        # your code\n",
        "\n",
        "        # you can copy paste the forward implementation from MultiHeadAttention\n",
        "        # then insert the implementation of the mask at the right place\n",
        "\n",
        "        return (context_vec, attn_weights) if self.output_attention_weights else (context_vec,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl5lGkxmAtSE"
      },
      "source": [
        "We create an instance of our CausalMultiHeadAttention class, we input the random embeddings and we save the outputs containing the attention weight matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmAH2mGaAtSH"
      },
      "outputs": [],
      "source": [
        "multihead_attention_block = CausalMultiHeadAttention(config_model[\"emb_dim\"], config_model[\"emb_dim\"], 0.1, num_heads = 2, output_attention_weights = True)\n",
        "contextualized_embeddings, attn_weights = multihead_attention_block(random_embeddings)\n",
        "\n",
        "print(f\"contextualized embeddings of shape {contextualized_embeddings.shape}\") # [batch_size, num_tokens, emb_dim]\n",
        "print(f\"attention weights of shape {attn_weights.shape}\") # [batch_size, n_heads, num_tokens, num_tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X0q_FlvAtSH"
      },
      "source": [
        "We visualize the attention weight matrices with the [interactive BertViz tool](https://github.com/jessevig/bertviz). Associated with our random initial embeddings, we randomly chose a sequence of \"Hello\" tokens. Note that, unlike the encoder example where tokens attend to all positions, the decoder ensures that tokens (on the left) DO NOT attend to future tokens in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDeXqY5iAtSH"
      },
      "outputs": [],
      "source": [
        "bertviz_attention_weight = (attn_weights[0].unsqueeze(0), ) # for 1st sentence\n",
        "bertviz_token_string = [\"Hello\"] * 11\n",
        "print(f\"attentions: {len(bertviz_attention_weight)} decoder layers, each with an attention matrix of shape {bertviz_attention_weight[0].shape}\")\n",
        "bertviz.model_view(bertviz_attention_weight, bertviz_token_string)\n",
        "bertviz.head_view(bertviz_attention_weight, bertviz_token_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv1jomUmAtSH"
      },
      "source": [
        "We don't observe much variation between the different attention heads since we did not train the model (the weights are randomly initialized).\n",
        "\n",
        "Now, let's visualize the attention weight matrices of the already pretrained GPT2 decoder model. Note again that a given token does not look at future tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aetUb_FYAtSH"
      },
      "outputs": [],
      "source": [
        "sentence = \"He turned off the fan whenever he felt too cold.\"\n",
        "inputs = tokenizer(sentence, add_special_tokens = False, return_tensors = \"pt\") # tokenization of the sentence\n",
        "attention = GPT2_model(**inputs).attentions # get the attention matrices\n",
        "token_ids = inputs['input_ids'][0].tolist() # extract the input ids at batch index 0\n",
        "tokens = tokenizer.batch_decode(token_ids) # convert the token ids to their string representation\n",
        "\n",
        "bertviz.model_view(attention, tokens)\n",
        "bertviz.head_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCRGj5cHAtSK"
      },
      "source": [
        "# Simple greedy text generation with a decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XTj_poIAtSK"
      },
      "source": [
        "In this section, we will implement a simple method to generate text with a decoder model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vERuOFoAtSK"
      },
      "source": [
        "First, we define a simple list of sequences that have been truncated. The goal is to use a decoder model to generate new tokens that extend these sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9oUZyMDAtSK"
      },
      "outputs": [],
      "source": [
        "simple_text_list = [\n",
        "    \"I love learning about science and\",\n",
        "    \"The 2025 Deep Learning School is\",\n",
        "    \"There are a lot of interesting\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwWPhi_PAtSK"
      },
      "source": [
        "Let's tokenize that text list and get the token IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kui_NF0xAtSK"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer(simple_text_list, add_special_tokens = False, return_tensors = \"pt\")[\"input_ids\"] # token IDs\n",
        "\n",
        "print(f\"\\nencoded text list of shape {input_ids.shape} =\\n{input_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dh8jzOAAtSK"
      },
      "source": [
        "We define a DecoderModelForGeneration class that takes as input a batch of tokenized sequences, processes it with a decoder model that outputs the contextualized embedding of each token (here, we will use the pretrained GPT2 decoder model), and adds a linear layer (generation head) that will output logits of size [batch_size, sequence_size, vocab_size]. These logits will be used for predicting the next tokens (which will be useful for pretraining and generating texts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98EeRF16AtSK"
      },
      "outputs": [],
      "source": [
        "class DecoderModelForGeneration(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "        base_model_name,\n",
        "        vocab_size,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.base_model_name = base_model_name\n",
        "        self.vocab_size = vocab_size\n",
        "        self.transformer = AutoModel.from_pretrained(base_model_name)\n",
        "        self.embedding_size = self.transformer.config.hidden_size\n",
        "        self.generation_head = torch.nn.Linear(self.embedding_size, self.vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, idx): # idx => [batch_size, num_tokens]\n",
        "        embeddings = self.transformer(idx).last_hidden_state # contextualized embedding for each token # [batch_size, num_tokens, embed_dim]\n",
        "        logits = self.generation_head(embeddings) # [batch_size, num_tokens, vocab_size]\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d7OH-m7AtSK"
      },
      "source": [
        "We instanciate our DecoderModelForGeneration class with the base decoder model GPT2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LVFgCr6AtSK"
      },
      "outputs": [],
      "source": [
        "my_model = DecoderModelForGeneration(\n",
        "    \"openai-community/gpt2\",\n",
        "    tokenizer.vocab_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIa90zZ4AtSL"
      },
      "outputs": [],
      "source": [
        "logits = my_model(input_ids)\n",
        "print(logits.shape, logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2xwrULbAtSL"
      },
      "source": [
        "We want to generate new tokens to extend the truncated simple text list. In order to do it, we first take into account only the logits of the last token of each sequence in the batch, which will later be used to predict the next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLKiwbKcArwT"
      },
      "source": [
        "Get those last-token logits. Logits were of dimension [batch_size, num_tokens, vocab_size], the last-token logits will be of dimension [batch_size, vocab_size]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWjKLd_YArwT"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "last_token_logits = ...\n",
        "print(\"last_token_logits:\", last_token_logits.shape, last_token_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKOcHV50AtSL"
      },
      "source": [
        "Then, use the [torch.argmax](https://pytorch.org/docs/main/generated/torch.argmax.html) function on the logits of the last token of each sequence to get the predicted most probable next token ID for each sequence in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUPbJzWkArwT"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "idx_next = ...\n",
        "print(\"idx_next:\", idx_next.shape, idx_next)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgbVii15AtSL"
      },
      "source": [
        "Append the predicted most probable token to each sequence. As `input_ids` was of dimension [3, 6], and we append at the end the predicted next token, we get a dimension of [3, 7]. You can use [torch.cat](https://docs.pytorch.org/docs/stable/generated/torch.cat.html) to concatenate the input token IDs and the next predicted token IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKwM47xtArwT"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "idx = ...\n",
        "print(\"input_ids\", input_ids.shape, input_ids)\n",
        "print(\"idx\", idx.shape, idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lt4402vArwU"
      },
      "source": [
        "We now decode the token IDs to get the beginning of the sentence and the next predicted subwords. Note that the generation head of our DecoderModelForGeneration instance has not been trained yet, therefore it outputs tokens that are not meaningful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB-Wibi0AtSL"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.batch_decode(idx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fal_CIHWAtSL"
      },
      "source": [
        "Reusing the code above, we define a simple generation function to produce tokens iteratively. Note that we use a for loop to generate not only 1 single tokens, but to successively generate several next tokens for each sequence. This is an autoregressive way to generate tokens at inference time. The decoding strategy that we use when selecting the next token is called \"greedy\", because take the most probable next token at each step.\n",
        "\n",
        "Note: A more complete version of this function would add a stopping criterion to stop the generation when encountering an EOS token (the End Of Sequence token). For the sake of simplicity, we do not implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8M7FhoYFgyy"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    idx = idx.to(device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the logits\n",
        "        with torch.inference_mode():\n",
        "            logits = ...\n",
        "\n",
        "        # Focus only on the last token in each sequence\n",
        "        # (batch_size, num_tokens, vocab_size) becomes (batch_size, vocab_size)\n",
        "        last_token_logits = ...\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = ...  # (batch_size, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = ...  # (batch_size, num_tokens + 1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcRaj5ETAtSM"
      },
      "source": [
        "We generate several next tokens for each sequence in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMxmP727AtSM"
      },
      "outputs": [],
      "source": [
        "max_new_tokens = 10 # to generate 10 more tokens\n",
        "generated_ids = generate_text_simple(my_model, input_ids, max_new_tokens, config_model[\"context_length\"], device)\n",
        "print(\"generated_ids:\", generated_ids.shape, generated_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MSJRIhIAtSM"
      },
      "source": [
        "We decode the now longer sequences (where more tokens have been generated). Note that the function outputs nonsensical next tokens because the generation head of the DecoderModelForGeneration model has not been trained yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp93Tc9oAtSM"
      },
      "outputs": [],
      "source": [
        "decoded_ids = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZoyjENAtSM"
      },
      "source": [
        "# Decoder pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlsPHyZtAtSM"
      },
      "source": [
        "In this section, we will pretrain the DecoderModelForGeneration model to generate new tokens. Note that the \"generation head\" has not been trained whatsoever, however, the GPT2 model in DecoderModelForGeneration has been already pretrained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SizTwquCAtSM"
      },
      "source": [
        "We download the text of \"[The Project Gutenberg eBook of The Adventures of Sherlock Holmes, by Arthur Conan Doyle](https://www.gutenberg.org/files/1661/1661-0.txt)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV6M8ghKAtSM"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.gutenberg.org/files/1661/1661-0.txt'\n",
        "resp = requests.get(url)\n",
        "raw_text = resp.text.replace(\"\\r\\n\", \" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vifm5b6AtSM"
      },
      "outputs": [],
      "source": [
        "print(raw_text[ : 2000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn_cGd-dAtSN"
      },
      "source": [
        "Split the text into a training part and and validation part. You can apply a very basic strategy: for instance, the first 80% of the text is the training text, and the last 20% of the text is the validation text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwpAJFCIArwW"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "train_ratio = 0.80 # Train/validation ratio\n",
        "\n",
        "train_text = ...\n",
        "val_text = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gZ0hz2CArwX"
      },
      "source": [
        "We use a Dataset where the text is tokenizer and divided into multiple chunks of size \"max_length\" and with a stride of \"stride\". The targets are the inputs but shifted one position forward, since we want to predict the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7J6x9KBArwX"
      },
      "outputs": [],
      "source": [
        "class DatasetPretraining(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer(txt, truncation = False, padding = False, add_special_tokens = False)[\"input_ids\"]\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F2BgKD8AtSN"
      },
      "source": [
        "We define a few key training elements, which may not be optimal but will still be effective for our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fZBIvE2AtSN"
      },
      "outputs": [],
      "source": [
        "my_model = DecoderModelForGeneration(\n",
        "    \"openai-community/gpt2\",\n",
        "    tokenizer.vocab_size,\n",
        ")\n",
        "\n",
        "traning_max_length = 1024\n",
        "training_stride = traning_max_length\n",
        "batch_size = 4\n",
        "nb_epochs = 4\n",
        "learning_rate = 5e-4\n",
        "optimizer = torch.optim.AdamW(my_model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ezCP8cUAtSN"
      },
      "source": [
        "We create our training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twUfDmBbAtSN"
      },
      "outputs": [],
      "source": [
        "train_dataset = DatasetPretraining(train_text, tokenizer, traning_max_length, training_stride)\n",
        "val_dataset = DatasetPretraining(val_text, tokenizer, traning_max_length, training_stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W89tGZPwAtSO"
      },
      "source": [
        "Note that the targets are the inputs but shifted one position forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxSv-AHZAtSO"
      },
      "outputs": [],
      "source": [
        "print(len(train_dataset))\n",
        "x, y = train_dataset[0]\n",
        "print(x.shape, x[:10])\n",
        "print(y.shape, y[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH3jJO3bAtSO"
      },
      "source": [
        "We create our training and validation dataloaders to automatically handle the batching process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve-RJWvGAtSO"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n0D0rbzAtSO"
      },
      "source": [
        "Now, we train our model to predict the next token. Remember that the defined training parameters are not ideal, and that we do not use a big enough dataset. However, you can still see that the model is learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jed-hzLpAtSM"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, val_dataloader, nb_epochs, device, optimizer):\n",
        "    training_validation_loss_history = {\"training_loss\" : [], \"validation_loss\" : []}\n",
        "    model = model.to(device)\n",
        "    initial_validation_loss = epoch_validation(model, val_dataloader, -1, device)\n",
        "    for epoch in range(nb_epochs):\n",
        "        training_loss = epoch_training(model, train_dataloader, epoch, device, optimizer)\n",
        "        validation_loss = epoch_validation(model, val_dataloader, epoch, device)\n",
        "        training_validation_loss_history[\"training_loss\"].append(training_loss)\n",
        "        training_validation_loss_history[\"validation_loss\"].append(validation_loss)\n",
        "    return training_validation_loss_history\n",
        "\n",
        "def epoch_training(model, dataloader, epoch, device, optimizer):\n",
        "    model.train()\n",
        "    loss_epoch_list = []\n",
        "    with tqdm(dataloader, unit=\"batch\") as tqdm_dataloader:\n",
        "        tqdm_dataloader.set_description(f\"Epoch {epoch}: Training\")\n",
        "        for input, target in tqdm_dataloader:\n",
        "            # load tensor to GPU if enabled\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass\n",
        "            logits = model(input)\n",
        "            # get the loss\n",
        "            loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            loss_epoch_list.append(loss.item())\n",
        "            loss_epoch_mean = sum(loss_epoch_list) / len(loss_epoch_list)\n",
        "            tqdm_dataloader.set_postfix(loss = loss_epoch_mean)\n",
        "            # backward pass, optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return loss_epoch_mean\n",
        "\n",
        "def epoch_validation(model, dataloader, epoch, device):\n",
        "    model.eval()\n",
        "    loss_epoch_list = []\n",
        "    with tqdm(dataloader, unit=\"batch\") as tqdm_dataloader, torch.inference_mode():\n",
        "        tqdm_dataloader.set_description(f\"Epoch {epoch}: Validation\")\n",
        "        for input, target in tqdm_dataloader:\n",
        "            # load tensor to GPU if enabled\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "            # forward pass\n",
        "            logits = model(input)\n",
        "            # get the loss\n",
        "            loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            loss_epoch_list.append(loss.item())\n",
        "            loss_epoch_mean = sum(loss_epoch_list) / len(loss_epoch_list)\n",
        "            tqdm_dataloader.set_postfix(loss = loss_epoch_mean)\n",
        "    return loss_epoch_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgNftvxVAtSO"
      },
      "outputs": [],
      "source": [
        "train(my_model, train_dataloader, val_dataloader, nb_epochs, device, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxg9H4YYAtSO"
      },
      "source": [
        "Let's test our trained model on the previous simple truncated text list. We will make the model generate new tokens. We notice that this time, the generation is much better than when the model was not trained. Note that the generation could have been better with a bigger dataset and better training parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftWW7DjUArwZ"
      },
      "outputs": [],
      "source": [
        "print(\"Initial simple truncated text list:\")\n",
        "print(simple_text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSfPq7m6AtSO"
      },
      "outputs": [],
      "source": [
        "max_new_tokens = 10 # to generate 10 more tokens\n",
        "generated_ids = generate_text_simple(my_model, input_ids, max_new_tokens, config_model[\"context_length\"], device)\n",
        "decoded_ids = tokenizer.batch_decode(generated_ids)\n",
        "print(\"text list completed with new generated tokens:\")\n",
        "print(decoded_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIi93K8tArwa"
      },
      "source": [
        "Now, let's use the already fully pretrained GPT-2 model, where the \"generation head\" has also already been fully trained on a huge corpus of texts, to generate the next few tokens completing the sentences. You can see that the generated tokens makes much more sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCDJYHBLArwa"
      },
      "outputs": [],
      "source": [
        "max_new_tokens = 10 # to generate a maximum of 10 more tokens\n",
        "generator = pipeline('text-generation', model='gpt2', device = device)\n",
        "print(generator(simple_text_list, truncation=True, max_new_tokens=max_new_tokens, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id, do_sample=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J48tWLHrAtSO"
      },
      "source": [
        "# Non-greedy decoding strategy: sampling with top_k and temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3b3BjtVAtSO"
      },
      "source": [
        "We used earlier the \"greedy\" text generation strategy, where, as explained earlier, the generated token is selected at each generation step corresponding to the largest probability score among all tokens in the vocabulary. This means that the LLM will always generate the same outputs even if we run the preceding generation function multiple times on the same start context.\n",
        "\n",
        "Let’s look at other common text generation strategies (also called decoding strategies) to generate more original text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skG9RcGlAtSO"
      },
      "source": [
        "We will look at two techniques:\n",
        "\n",
        "- Top-k sampling is a technique that leverages the probability distribution generated by the language model to select a token from the k most likely options.\n",
        "\n",
        "- We can further control the distribution and selection process via a concept called temperature scaling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUie4v9tAtSP"
      },
      "source": [
        "## Sampling with temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GclPRbhAtSP"
      },
      "source": [
        "Let’s now look at temperature scaling, a technique that adds a probabilistic selection process to the next-token generation task. Previously, we always sampled the token with the highest probability as the next token using torch.argmax, also known as greedy decoding. To generate text with more variety, we can replace torch.argmax with a function that samples from a probability distribution (here, the probability scores the LLM generates for each token ID at each token generation step)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrIFEhoTAtSP"
      },
      "source": [
        "To illustrate the probabilistic sampling with a concrete example, let’s briefly discuss the next-token generation process using a very small vocabulary for illustration\n",
        "purposes:\n",
        "\n",
        "Fist, for illustration purposes, we show an example on a very small vocabulary, and we write ourself the logits of the next token hypothetically outputted by a LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCksZsv3AtSP"
      },
      "outputs": [],
      "source": [
        "vocab = {\n",
        "    \"Welcome\": 0,\n",
        "    \"to\": 1,\n",
        "    \"the\": 2,\n",
        "    \"amazing\": 3,\n",
        "    \"2025\": 4,\n",
        "    \"Deep\": 5,\n",
        "    \"Learning\": 6,\n",
        "    \"School\": 7,\n",
        "    \"!\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmiHdQ_PAtSP"
      },
      "source": [
        "In the greedy decoding strategy (without using sampling), we converted the logits into probabilities via the softmax function and obtain the token ID corresponding to the generated token via the argmax function, which we could then map back into text via the inverse vocabulary.\n",
        "\n",
        "For a given sequence start, the generated next token is always the same, no matter how many times we run the code, because it's deterministic, no randomness is introduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uoK5jRRAtSP"
      },
      "outputs": [],
      "source": [
        "# greedy decoding\n",
        "probas = torch.softmax(next_token_logits, dim=-1)\n",
        "print(\"probas:\", probas)\n",
        "next_token_id = torch.argmax(probas, dim = -1).item()\n",
        "print(\"next_token_id:\", next_token_id)\n",
        "print(\"next token:\", inverse_vocab[next_token_id]) # always the same predicted next token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_VuElOwAtSP"
      },
      "source": [
        "To implement a probabilistic sampling process, we can now replace torch.argmax with the [torch.multinomial](https://pytorch.org/docs/stable/generated/torch.multinomial.html) function in PyTorch.\n",
        "\n",
        "Run sereval times the following piece of code, and observe that the generated next token do change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3k7X5MsAtSP"
      },
      "outputs": [],
      "source": [
        "probas = torch.softmax(next_token_logits, dim=-1)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(\"next token:\", inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLfKWVpmAtSQ"
      },
      "source": [
        "To better visualize the probabilities for the next token, let’s repeats this sampling \"number_of_tests\" = 1,000 times. We display how many times the words in the vocabulary have been selected as the next token.\n",
        "\n",
        "We also add the temperature scaling. Temperature scaling is just dividing the logits by a number greater than 0. A temperature of 1 divides the logits by 1 before passing them to the softmax function to compute the probability scores. In other words, using a temperature of 1 is the same as not using any temperature scaling.\n",
        "\n",
        "Test the next token distribution with different values for the temperature (for instance: 0.1, 1, 5, etc). How does the distribution of the next token changes depending on the temperature ? What does it mean to have a low temperature ? And a high temperature ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1DQKuQrAtSQ"
      },
      "outputs": [],
      "source": [
        "temperature = 1.0\n",
        "number_of_tests = 1000\n",
        "\n",
        "scaled_next_token_logits = next_token_logits / temperature\n",
        "probas = torch.softmax(scaled_next_token_logits, dim=-1)\n",
        "next_token_id_list = torch.multinomial(probas, num_samples = number_of_tests, replacement = True).tolist()\n",
        "next_token_list = [inverse_vocab[next_token_id] for next_token_id in next_token_id_list]\n",
        "\n",
        "print(Counter(next_token_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAbClF6GAtSQ"
      },
      "source": [
        "Temperatures greater than 1 result in more uniformly distributed token probabilities, and temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions. We illustrate this by plotting the probabilities scaled with different temperature values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYU_kE9KAtSQ"
      },
      "outputs": [],
      "source": [
        "temperatures = [1, 0.1, 5]\n",
        "scaled_probas = [torch.softmax(next_token_logits / T, dim=-1) for T in temperatures]\n",
        "\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
        "    bar_width, label=f'Temperature = {T}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ltvi5-hAtSQ"
      },
      "source": [
        "## top_k sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUQk0ILnAtSQ"
      },
      "source": [
        "We previously implemented a probabilistic sampling approach coupled with temperature scaling to increase the diversity of the outputs. This method allows for the exploring of less likely but potentially more interesting and creative paths in the generation process. However, one downside of this approach is that it sometimes leads to grammatically incorrect or completely nonsensical output.\n",
        "\n",
        "Top-k sampling, when combined with probabilistic sampling and temperature scaling, can improve the text generation results. In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens and exclude all other tokens from the selection process by masking their probability scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6XAW66IAtSQ"
      },
      "source": [
        "Using top-k sampling with k = 3, we focus on the three tokens associated with the highest logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaFgoXeSAtSQ"
      },
      "outputs": [],
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Initial logits:\", next_token_logits)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHZQ-_ByAtSQ"
      },
      "source": [
        "We then mask out all other tokens with negative infinity (–inf). In other words, we apply [torch.where](https://pytorch.org/docs/stable/generated/torch.where.html) function to set the logit values of tokens that are below the lowest logit value within our top-three selection to negative infinity (-inf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_BLIAd1AtSR"
      },
      "outputs": [],
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1], # Identifies logits less than the minimum in the top n\n",
        "    input=torch.tensor(float('-inf')), # Assigns –inf to these lower logits\n",
        "    other=next_token_logits # Retains the original logits for all other tokens\n",
        ")\n",
        "\n",
        "print(new_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw91wtNZAtSR"
      },
      "source": [
        "Lastly, we apply the softmax function to turn these new logits into next-token probabilities. As we can see, the result of this top-three approach are three non-zero probability scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVD2c1L0AtSR"
      },
      "outputs": [],
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=-1)\n",
        "print(topk_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3WqItRWAtSR"
      },
      "source": [
        "We can now apply the temperature scaling and multinomial function for probabilistic sampling to select the next token among these three non-zero probability scores to generate the next token. We do this next by modifying the text generation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGu9MyHiAtSR"
      },
      "source": [
        "## Combining top_k sampling with temperature for next token generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAzIagDMAtSR"
      },
      "source": [
        "We combine temperature sampling and top-k sampling for a more advanced text generation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcd3aPU4AtSR"
      },
      "outputs": [],
      "source": [
        "def generate_advanced(model, idx, max_new_tokens, context_size, device, temperature=0.0, top_k=None):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    idx = idx.to(device)\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, top_pos = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1] # miminum logits values to be retrained\n",
        "            logits = torch.where(\n",
        "                condition = logits < min_val.unsqueeze(dim = -1), # Identifies logits less than the minimum in the top n\n",
        "                input = torch.tensor(float(\"-inf\")).to(device), # Assigns –inf to these lower logits\n",
        "                other = logits # Retains the original logits for all other tokens\n",
        "            )\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhdpZcLVAtSR"
      },
      "source": [
        "You can try different temperature and top_k values and see the generated tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpcTSnCdAtSR"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "temperature = ...\n",
        "top_k = ...\n",
        "max_new_tokens = 10 # to generate 10 more tokens\n",
        "generated_ids = generate_advanced(my_model, input_ids, max_new_tokens, config_model[\"context_length\"], device, temperature = temperature, top_k = top_k)\n",
        "decoded_ids = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded_ids)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8c523971fd845939993e9144a5139eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6563a0c2a294c11b483987484bc4a51",
              "IPY_MODEL_341e5e93a626419c96846ff01c7e7124",
              "IPY_MODEL_3c478be8774d4011b6e6f2f3f379134e"
            ],
            "layout": "IPY_MODEL_dd1d67ffff9e42cfabef92adc63feb7f"
          }
        },
        "d6563a0c2a294c11b483987484bc4a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f8d472b34a42ebbf655940f68e2d48",
            "placeholder": "​",
            "style": "IPY_MODEL_f04aaba5c50848548d4dc6c3a58d30e1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "341e5e93a626419c96846ff01c7e7124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8b0bcd55b148ec9895fc316945d7f1",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecfa102a568c42ef99956bba507e45f9",
            "value": 26
          }
        },
        "3c478be8774d4011b6e6f2f3f379134e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f5921576ba481d92f258b663823f3c",
            "placeholder": "​",
            "style": "IPY_MODEL_2c0557fd332847a4b2f4a7feb2a03de0",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.06kB/s]"
          }
        },
        "dd1d67ffff9e42cfabef92adc63feb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f8d472b34a42ebbf655940f68e2d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04aaba5c50848548d4dc6c3a58d30e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8b0bcd55b148ec9895fc316945d7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecfa102a568c42ef99956bba507e45f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4f5921576ba481d92f258b663823f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c0557fd332847a4b2f4a7feb2a03de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6226e48b387248a0b984c2cbdc067893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84ec0456a72d4b43a6cb85b79e067ebd",
              "IPY_MODEL_bfff00db34a44e6a946ff58bc3a1892f",
              "IPY_MODEL_b31e9c6ec24f4ac794996bd849cfdfe4"
            ],
            "layout": "IPY_MODEL_00e694b67e524e53930b82628f299271"
          }
        },
        "84ec0456a72d4b43a6cb85b79e067ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2faf1c55494a7caa76f816db80fb0f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7eefe67152146058c081a5202710865",
            "value": "config.json: 100%"
          }
        },
        "bfff00db34a44e6a946ff58bc3a1892f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da5d2388028847d89ca0fde6e2ee90c6",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5c797dfd5724c8988eb49faad3d0fc9",
            "value": 665
          }
        },
        "b31e9c6ec24f4ac794996bd849cfdfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd8041bd2ebc465c8d965887e0df88ef",
            "placeholder": "​",
            "style": "IPY_MODEL_0932235d50354d5d8ae914003497c88c",
            "value": " 665/665 [00:00&lt;00:00, 41.4kB/s]"
          }
        },
        "00e694b67e524e53930b82628f299271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2faf1c55494a7caa76f816db80fb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7eefe67152146058c081a5202710865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5d2388028847d89ca0fde6e2ee90c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c797dfd5724c8988eb49faad3d0fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd8041bd2ebc465c8d965887e0df88ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0932235d50354d5d8ae914003497c88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b0048539c40491b90aaef202a1711e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84ddd951cfa242ef8eb630ab6b76c70b",
              "IPY_MODEL_21312f3035d8470bb359349b35510922",
              "IPY_MODEL_c42fc53dd46c4d98becc91997e0b8f8c"
            ],
            "layout": "IPY_MODEL_d41af6102e284b569318961580dd922c"
          }
        },
        "84ddd951cfa242ef8eb630ab6b76c70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47f67352e07402d963436e7cd3ec8c4",
            "placeholder": "​",
            "style": "IPY_MODEL_6f984a82a0af4370b0d9040dbab75ee3",
            "value": "vocab.json: 100%"
          }
        },
        "21312f3035d8470bb359349b35510922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5efc2e6763d413aa1d4a8cd02da692a",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e2dd6cbd5244cae9c344bd50cfcbd6c",
            "value": 1042301
          }
        },
        "c42fc53dd46c4d98becc91997e0b8f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5ce8474f7a43aaa14e6dee0fc70e41",
            "placeholder": "​",
            "style": "IPY_MODEL_93c899e68a534ab09ea565c26374c4bc",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 7.18MB/s]"
          }
        },
        "d41af6102e284b569318961580dd922c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47f67352e07402d963436e7cd3ec8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f984a82a0af4370b0d9040dbab75ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5efc2e6763d413aa1d4a8cd02da692a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2dd6cbd5244cae9c344bd50cfcbd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c5ce8474f7a43aaa14e6dee0fc70e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c899e68a534ab09ea565c26374c4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d066d13e5964144b06461962bc2145f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c3b07c72bc34bcab69c694692138135",
              "IPY_MODEL_e4708c17451d46459769665f900d3cbc",
              "IPY_MODEL_7c1556140ffe46c9b354015b11436ccd"
            ],
            "layout": "IPY_MODEL_41808acf48ae46d6b92e281b5b13b063"
          }
        },
        "8c3b07c72bc34bcab69c694692138135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2276528dd5214d9485fca32830999f0e",
            "placeholder": "​",
            "style": "IPY_MODEL_c60700cbc8234eee95341cc367f07301",
            "value": "merges.txt: 100%"
          }
        },
        "e4708c17451d46459769665f900d3cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11c65cd636b14eb3bb16620d9909a534",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfe496d5a7a2487f8e09900aec32ad47",
            "value": 456318
          }
        },
        "7c1556140ffe46c9b354015b11436ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f687a4d3bc3a4b34ad628c9082735f79",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f85baaa4e04e348e629ed12bef1678",
            "value": " 456k/456k [00:00&lt;00:00, 3.62MB/s]"
          }
        },
        "41808acf48ae46d6b92e281b5b13b063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2276528dd5214d9485fca32830999f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60700cbc8234eee95341cc367f07301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c65cd636b14eb3bb16620d9909a534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe496d5a7a2487f8e09900aec32ad47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f687a4d3bc3a4b34ad628c9082735f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f85baaa4e04e348e629ed12bef1678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "736d2f239d0749bf9d485eb65b18eeab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d4b27d925e04a558930ad88430e4627",
              "IPY_MODEL_aef669c3f1ee4c5ebace644ef5a50c6a",
              "IPY_MODEL_840c74ca21cd45daa51a5fcf52972ba0"
            ],
            "layout": "IPY_MODEL_bb8452d3b33c4904a240bf085664fc5a"
          }
        },
        "2d4b27d925e04a558930ad88430e4627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18cf0d887fdc4fe78f837e0c020cf876",
            "placeholder": "​",
            "style": "IPY_MODEL_fb111fcc89744dcc91ce942c3a018561",
            "value": "tokenizer.json: 100%"
          }
        },
        "aef669c3f1ee4c5ebace644ef5a50c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10422ab055974b9082726c2bfae18aa8",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0cfd2b3610c47d9a19feaf2a3ba13fc",
            "value": 1355256
          }
        },
        "840c74ca21cd45daa51a5fcf52972ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_224fae8dc3444eb1854cd08f1505cf9a",
            "placeholder": "​",
            "style": "IPY_MODEL_ff14000023fe4b65b3b3a1699563d63b",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 6.29MB/s]"
          }
        },
        "bb8452d3b33c4904a240bf085664fc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18cf0d887fdc4fe78f837e0c020cf876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb111fcc89744dcc91ce942c3a018561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10422ab055974b9082726c2bfae18aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0cfd2b3610c47d9a19feaf2a3ba13fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "224fae8dc3444eb1854cd08f1505cf9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff14000023fe4b65b3b3a1699563d63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8521000fbc094d9d9d0d4635fd7b32ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fff7344cd87644278d1d60eb2becbf32",
              "IPY_MODEL_b799f74dc95e4aeaa8383de3945c80b9",
              "IPY_MODEL_dcc598a34d644b068f1eba2747b6a335"
            ],
            "layout": "IPY_MODEL_9373a2ca7c5242fe961ba4b026dda154"
          }
        },
        "fff7344cd87644278d1d60eb2becbf32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9753eb2fae6d4766b10524f68bd9ca14",
            "placeholder": "​",
            "style": "IPY_MODEL_5fe132b235f94d1e8c060cb6dd1372c6",
            "value": "model.safetensors: 100%"
          }
        },
        "b799f74dc95e4aeaa8383de3945c80b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c5dcf85aa24a80a6d59e3d4239b502",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_779e6f285901432d85629708011c056d",
            "value": 548105171
          }
        },
        "dcc598a34d644b068f1eba2747b6a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1288eeacd644b291839c0b342c33c5",
            "placeholder": "​",
            "style": "IPY_MODEL_c0f92c727c8342c6977df0efb83283a9",
            "value": " 548M/548M [00:11&lt;00:00, 83.1MB/s]"
          }
        },
        "9373a2ca7c5242fe961ba4b026dda154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9753eb2fae6d4766b10524f68bd9ca14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe132b235f94d1e8c060cb6dd1372c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9c5dcf85aa24a80a6d59e3d4239b502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779e6f285901432d85629708011c056d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd1288eeacd644b291839c0b342c33c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0f92c727c8342c6977df0efb83283a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}